#!/usr/bin/env python3

import hydra
import importlib
import os
import torch
import transformers
import argparse
from pathlib import Path

import logging

log = logging.getLogger()


from lm_polygraph.utils.manager import UEManager
from lm_polygraph.utils.dataset import Dataset
from lm_polygraph.utils.model import WhiteboxModel
from lm_polygraph.utils.processor import Logger
from lm_polygraph.generation_metrics import (
    RougeMetric,
    WERTokenwiseMetric,
    BartScoreSeqMetric,
    ModelScoreSeqMetric,
    ModelScoreTokenwiseMetric,
)
from lm_polygraph.estimators import *
from lm_polygraph.ue_metrics import (
    ReversedPairsProportion,
    PredictionRejectionArea,
    RiskCoverageCurveAUC,
)


def get_args():
    parser = argparse.ArgumentParser()

    parser.add_argument("--dataset", type=str)
    parser.add_argument("--train_dataset", type=str)
    parser.add_argument("--background_train_dataset", type=str)
    parser.add_argument("--model", type=str)
    parser.add_argument(
        "--use_density_based_ue",
        type=bool,
        default=True,
        action=argparse.BooleanOptionalAction,
    )
    parser.add_argument(
        "--ignore_exceptions",
        type=bool,
        default=True,
        action=argparse.BooleanOptionalAction,
    )
    parser.add_argument("--subsample_background_train_dataset", type=int, default=1000)
    parser.add_argument("--subsample_train_dataset", type=int, default=100)
    parser.add_argument("--subsample_eval_dataset", type=int, default=100)
    parser.add_argument("--batch_size", type=int, default=2)
    parser.add_argument("--seed", nargs="+", type=int)
    parser.add_argument("--device", type=str, default=None)
    parser.add_argument("--save_path", type=str, default="")
    parser.add_argument("--cache_path", type=str, default="")

    args = parser.parse_args()

    return args


def main_run(config, save_path):
    args = get_args() if config is None else config
    save_path = args.save_path if "save_path" in args else save_path

    additional_estimators = []
    for module_name, estimators in getattr(args, "additional_estimators", {}).items():
        module = importlib.import_module(module_name)
        for estimator in estimators:
            additional_estimators.append(getattr(module, estimator)())

    if args.seed is None or len(args.seed) == 0:
        args.seed = [1]

    device = args.device
    if device is None:
        device = "cuda:0" if torch.cuda.device_count() > 0 else "cpu"

    for seed in args.seed:
        log.info("=" * 100)
        log.info(f"SEED: {seed}")

        log.info(f"Loading model {args.model}...")
        transformers.set_seed(seed)
        model = WhiteboxModel.from_pretrained(
            args.model,
            device=device,
        )
        log.info("Done with loading model.")

        log.info(f"Loading dataset {args.dataset}...")
        dataset = Dataset.load(
            args.dataset,
            "question",
            "answer",
            batch_size=args.batch_size,
        )

        if args.use_density_based_ue:
            if (args.train_dataset is not None) and (
                args.train_dataset != args.dataset
            ):
                train_dataset = Dataset.load(
                    args.train_dataset,
                    "question",
                    "answer",
                    batch_size=args.batch_size,
                )
            else:
                X_train, X_test, y_train, y_test = dataset.train_test_split(
                    test_size=0.7, seed=seed, split="eval"  # TODO: !
                )
                train_dataset = Dataset(
                    x=X_train, y=y_train, batch_size=args.batch_size
                )
                
            background_train_dataset = Dataset.load(
                args.background_train_dataset,
                "text",
                "url",
                batch_size=args.batch_size,
                data={
                    "data_files": "en/c4-train.00000-of-01024.json.gz"
                },  # TODO: What is this ????
                max_size=100_000,  # TODO:!
                split="train",
            )

            if args.subsample_train_dataset != -1:
                train_dataset.subsample(args.subsample_train_dataset, seed=seed)
            if args.subsample_background_train_dataset != -1:
                background_train_dataset.subsample(
                    args.subsample_background_train_dataset, seed=seed
                )

            log.info("Done with loading data.")

            dataset_name = args.dataset.split("/")[-1].split(".")[0]
            model_name = args.model.split("/")[-1]
            parameters_path = f"{args.cache_path}/{dataset_name}/{model_name}"

            if model.model_type == "Seq2SeqLM":
                density_based_ue = [
                    MahalanobisDistanceSeq("encoder", parameters_path=parameters_path),
                    MahalanobisDistanceSeq("decoder", parameters_path=parameters_path),
                    RelativeMahalanobisDistanceSeq(
                        "encoder", parameters_path=parameters_path
                    ),
                    RelativeMahalanobisDistanceSeq(
                        "decoder", parameters_path=parameters_path
                    ),
                    RDESeq("encoder", parameters_path=parameters_path),
                    RDESeq("decoder", parameters_path=parameters_path),
                    PPLMDSeq("encoder", md_type="MD", parameters_path=parameters_path),
                    PPLMDSeq("encoder", md_type="RMD", parameters_path=parameters_path),
                    PPLMDSeq("decoder", md_type="MD", parameters_path=parameters_path),
                    PPLMDSeq("decoder", md_type="RMD", parameters_path=parameters_path),
                ]
            else:
                density_based_ue = [
                    MahalanobisDistanceSeq("decoder", parameters_path=parameters_path),
                    RelativeMahalanobisDistanceSeq(
                        "decoder", parameters_path=parameters_path
                    ),
                    RDESeq("decoder", parameters_path=parameters_path),
                    PPLMDSeq("decoder", md_type="MD", parameters_path=parameters_path),
                    PPLMDSeq("decoder", md_type="RMD", parameters_path=parameters_path),
                ]
        else:
            train_dataset = None
            background_train_dataset = None
            density_based_ue = []

        if args.subsample_eval_dataset != -1:
            dataset.subsample(args.subsample_eval_dataset, seed=seed)

        man = UEManager(
            dataset,
            model,
            [
                MaximumSequenceProbability(),
                Perplexity(),
                MeanTokenEntropy(),
                MeanPointwiseMutualInformation(),
                MeanConditionalPointwiseMutualInformation(tau=0.0656, lambd=3.599),
                PTrue(),
                PTrueSampling(),
                MonteCarloSequenceEntropy(),
                MonteCarloNormalizedSequenceEntropy(),
                LexicalSimilarity(metric="rouge1"),
                LexicalSimilarity(metric="rouge2"),
                LexicalSimilarity(metric="rougeL"),
                LexicalSimilarity(metric="BLEU"),
                NumSemSets(),
                EigValLaplacian(similarity_score="NLI_score", affinity="entail"),
                EigValLaplacian(similarity_score="NLI_score", affinity="contra"),
                EigValLaplacian(similarity_score="Jaccard_score"),
                DegMat(similarity_score="NLI_score", affinity="entail"),
                DegMat(similarity_score="NLI_score", affinity="contra"),
                DegMat(similarity_score="Jaccard_score"),
                Eccentricity(similarity_score="NLI_score", affinity="entail"),
                Eccentricity(similarity_score="NLI_score", affinity="contra"),
                Eccentricity(similarity_score="Jaccard_score"),
                SemanticEntropy(),
                MaximumTokenProbability(),
                TokenEntropy(),
                PointwiseMutualInformation(),
                ConditionalPointwiseMutualInformation(
                    tau=0.0656, lambd=3.599
                ),  # TODO: What is this ????
                SemanticEntropyToken(model.model_path, args.cache_path),
            ]
            + density_based_ue
            + additional_estimators,
            [
                RougeMetric("rouge1"),
                RougeMetric("rouge2"),
                RougeMetric("rougeL"),
                BartScoreSeqMetric("rh"),
                ModelScoreSeqMetric("model_rh"),
                ModelScoreTokenwiseMetric("model_rh"),
                WERTokenwiseMetric(),
            ],
            [
                ReversedPairsProportion(),
                PredictionRejectionArea(),
                RiskCoverageCurveAUC(),
            ],
            [
                Logger(),
            ],
            train_data=train_dataset,
            ignore_exceptions=args.ignore_exceptions,
            background_train_data=background_train_dataset,
        )

        man()

        man.save(save_path + f"_seed{seed}")


if "HYDRA_CONFIG" in os.environ:
    hydra_config = Path(os.environ["HYDRA_CONFIG"])

    @hydra.main(
        version_base=None,
        config_path=str(hydra_config.parent),
        config_name=str(hydra_config.name),
    )
    def main_hydra(config):
        output_dir = os.getcwd()
        print(output_dir)
        os.chdir(hydra.utils.get_original_cwd())
        main_run(config, output_dir)

    main = main_hydra

else:
    main = lambda: main_run(None, None)


if __name__ == "__main__":
    main()
