#!/usr/bin/env python3

import hydra
import os
import sys
import json
import math
from pathlib import Path

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import spearmanr, binned_statistic, sem
from scipy import ndimage as nd
from scipy.signal import savgol_filter

from lm_polygraph.utils.manager import UEManager
import logging

log = logging.getLogger()
HYDRA_CONFIG = Path(os.environ["HYDRA_CONFIG"])


@hydra.main(
    version_base=None,
    config_path=str(HYDRA_CONFIG.parent),
    config_name=str(HYDRA_CONFIG.name),
)
def main(args):
    out = Path(args.save_path)
    log.info(f"Main directory: {out}")
    os.chdir(hydra.utils.get_original_cwd())

    ues = args.ue_methods
    gen_metrics_names = args.generation_metrics
    num_bins = args.num_bins

    do_smooth = args.smoothing.do_smooth
    bins_per_window = args.smoothing.bins_per_window
    
    # Get all ues and gen_metrics from all managers
    full_estimations, full_gen_metrics = get_man_data(args.manager_paths) 
    
    # Perform calibration using the concatenated data
    perform_calibration(full_estimations,
                        full_gen_metrics,
                        ues, gen_metrics_names,
                        out, num_bins, do_smooth=do_smooth,
                        bins_per_window=bins_per_window)


def fill(data, invalid=None):
    """
    Replace the value of invalid 'data' cells (indicated by 'invalid') 
    by the value of the nearest valid data cell

    Input:
        data:    numpy array of any dimension
        invalid: a binary array of same shape as 'data'. 
                 data value are replaced where invalid is True
                 If None (default), use: invalid  = np.isnan(data)

    Output: 
        Return a filled array. 
    """
    if invalid is None: invalid = np.isnan(data)

    ind = nd.distance_transform_edt(invalid, 
                                    return_distances=False, 
                                    return_indices=True)
    return data[tuple(ind)]


def normalize_metric(metric):
    return (metric - metric.min()) / (metric.max() - metric.min())


def smooth_and_normalize(metric, window_size, smooth=True):
    if smooth:
        metric = savgol_filter(metric, window_size, 3)
   
    unnormalized_conf = metric
    normalized_conf = normalize_metric(unnormalized_conf) 

    return normalized_conf, unnormalized_conf


def get_metric_and_ue(metric_name, ue_name, estimations, gen_metrics):
    # change metric and ue names to tuple to match the format of the estimations and gen_metrics
    metric_name = ('sequence', metric_name)
    metrics = []
    ue_name = ('sequence', ue_name)
    ues = []
    
    # Concatenate metrics and ues values from all the managers
    for man_estimations, man_gen_metrics in zip(estimations, gen_metrics):
        metrics.append(man_gen_metrics[metric_name])
        ues.append(np.array(man_estimations[ue_name]))

    metric = np.concatenate(metrics)
    ue = np.concatenate(ues)

    # Remove nans from the data
    nans = np.isnan(ue) | np.isnan(metric)
    filtered_ue = ue[~nans]
    filtered_metric = metric[~nans]

    return filtered_ue, filtered_metric, normed_metric


def get_bin_indices(ue, num_bins):
    per_bin = len(ue) / num_bins

    lesser_bin = math.floor(per_bin)
    greater_bin = math.ceil(per_bin)

    n_lesser_bins = (greater_bin * num_bins) - len(ue)
    n_greater_bins = num_bins - n_lesser_bins
    
    greater_start_index = n_lesser_bins * lesser_bin
    bin_indices = [i * lesser_bin for i in range(n_lesser_bins)] + \
                  [greater_start_index + i * greater_bin for i in range(n_greater_bins)]

    return bin_indices


def get_bin_edges(ue, num_bins):
    sorted_ue = np.sort(ue)
    bin_indices = get_bin_indices(sorted_ue, num_bins)
    bin_edges = [sorted_ue[i] for i in bin_indices]
    
    return bin_edges

def get_bins(ue, metric, edges):
    metric_bins = binned_statistic(ue,
                                   metric,
                                   bins=edges,
                                   statistic='mean')

    std_bins = binned_statistic(ue,
                                metric,
                                bins=edges,
                                statistic='std')

    sem_bins = binned_statistic(ue,
                                metric,
                                bins=edges,
                                statistic=sem)

    return metric_bins, std_bins, sem_bins


def plot(metric_bins, std_bins, sem_bins, normalized_conf, plot_name, out, metric_name):
    fig, ax = plt.subplots(4, 1, figsize=(5, 18))
    fig.suptitle(plot_name)

    ax[0].plot(range(len(metric_bins)), metric_bins)
    ax[0].set_ylabel(metric_name)
    ax[0].set_xlabel('Bin')
    ax[0].grid()

    ax[1].plot(range(len(std_bins)), std_bins)
    ax[1].set_ylabel(f'{metric_name} StD')
    ax[1].set_xlabel('Bin')
    ax[1].grid()

    ax[2].plot(range(len(sem_bins)), sem_bins)
    ax[2].set_ylabel(f'{metric_name} Standard Error')
    ax[2].set_xlabel('Bin')
    ax[2].grid()

    ax[3].plot(range(len(normalized_conf)), normalized_conf)
    ax[3].set_ylabel('Normalized conf, %')
    ax[3].set_xlabel('Bin')
    ax[3].grid()

    plt.tight_layout()
    plt.savefig(out / (plot_name + '.png'))
    plt.clf()


def perform_calibration(estimations, gen_metrics, ues, metric_names, out=None, num_bins=100, do_smooth=True, bins_per_window=25):
    all_archives = {}
    for metric_name in metric_names:
        archive = {}

        for i, ue_name in enumerate(ues):
            # Get the metric and ue values for the current metric and ue method
            filtered_ue, filtered_metric, normed_metric = get_metric_and_ue(metric_name, ue_name, estimations, gen_metrics)
            
            # Get the bin edges for the ue values ensuring that each bin has the same number of ue values
            bin_edges = get_bin_edges(filtered_ue, num_bins)
            # Perform binning of the metric values
            metric_bins, std_bins, sem_bins = get_bins(filtered_ue, normed_metric, bin_edges)

            # Get the mean, standard deviation and standard error of the metric values in each bin
            binned_metric = metric_bins.statistic
            binned_std = std_bins.statistic
            binned_sem = sem_bins.statistic
            
            # Smooth and normalize the metric values to [0, 1]
            normalized_conf, unnormalized_conf = smooth_and_normalize(binned_metric, bins_per_window, smooth=do_smooth)

            if out is not None:
                plot(binned_metric, binned_std, binned_sem, normalized_conf,
                     f'{ue_name}_{metric_name}', out, metric_name)

            archive[ue_name] = {
                'ues': list(metric_bins.bin_edges), # bin edges to select the bin
                'metric': list(binned_metric), # mean metric value in each bin
                'normed_conf': list(normalized_conf), # normalized confidence in each bin
                'unnormed_conf': list(unnormalized_conf), # unnormalized confidence in each bin
            }

        all_archives[metric_name] = archive

        if out is not None:
            with open(out / f'{metric_name}_calibrated_ues.json', 'w') as handle:
                handle.write(json.dumps(archive))

    return all_archives


def get_man_data(man_paths):
    mans = [UEManager.load(man_path) for man_path in man_paths]
    estimations = [man.estimations for man in mans]
    gen_metrics = [man.gen_metrics for man in mans]

    return estimations, gen_metrics

if __name__ == "__main__":
    main()
