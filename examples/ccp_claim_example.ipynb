{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acb062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b1d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = \"cuda:0\"\n",
    "batch_size = 2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6560b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7ae864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce839b34a174d55a44b7c558e1dd02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c9801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me a bio of Albert Einstein.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Alla Pugacheva.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Paul McCartney\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2086aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-17 20:42:50.888094: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-17 20:42:51.212555: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-17 20:42:51.212596: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-17 20:42:51.214386: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-17 20:42:51.390250: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-17 20:42:52.550223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from lm_polygraph.model_adapters import WhiteBoxModelBasic\n",
    "from lm_polygraph.estimators import ClaimConditionedProbabilityClaim\n",
    "from lm_polygraph.stat_calculators import *\n",
    "from lm_polygraph.utils.openai_chat import OpenAIChat\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "\n",
    "\n",
    "model_adapter = WhiteBoxModelBasic(model, tokenizer)\n",
    "\n",
    "calc_infer_llm = InferCausalLMCalculator(tokenize=False)\n",
    "\n",
    "os.environ[\"OPENAI_KEY\"] = \"<Your key>\"\n",
    "calc_claim_extractor = ClaimsExtractor(OpenAIChat(\"gpt-4\"))\n",
    "\n",
    "calc_claim_nli = GreedyAlternativesNLICalculator(Deberta())\n",
    "\n",
    "estimator = ClaimConditionedProbabilityClaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d705c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1636: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Albert Einstein (14 March 1879 – 18 April 1955) was a German-born theoretical physicist who is widely recognized as one of the most influential scientists in history. He is best known for developing the theory of general relativity, one of the two pillars of modern physics (alongside quantum mechanics). He is also known for his mass–energy equivalence formula E = mc², which has been dubbed \"the world\n",
      "claim: Albert Einstein was born on 14 March 1879.\n",
      "aligned tokens: [0, 1, 3, 4, 5]\n",
      "UE score: -0.5041567570910105\n",
      "claim: Albert Einstein died on 18 April 1955.\n",
      "aligned tokens: [0, 1]\n",
      "UE score: -0.9999800427529746\n",
      "claim: He is best known for developing the theory of general relativity.\n",
      "aligned tokens: [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "UE score: -0.9967017976298952\n",
      "claim: The theory of general relativity is one of the two pillars of modern physics.\n",
      "aligned tokens: [50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66]\n",
      "UE score: -0.9981486797756218\n",
      "claim: The two pillars of modern physics are general relativity and quantum mechanics.\n",
      "aligned tokens: [52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 71, 72]\n",
      "UE score: -0.9968378064007372\n",
      "\n",
      "Output: Alla Borisovna Pugacheva, born on September 17, 1949, in Leningrad, Soviet Union (now St. Petersburg, Russia), is a renowned Russian singer, actress, and television personality. She is often referred to as the \"Queen of Russian Song\" and is one of the most popular and influential figures in Russian entertainment.\n",
      "\n",
      "Pugacheva began her career in the late 1960s,\n",
      "claim: Alla Borisovna Pugacheva was born.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11]\n",
      "UE score: -0.3557108081125955\n",
      "claim: Her birthdate is September 17, 1949.\n",
      "aligned tokens: [11, 12, 13]\n",
      "UE score: -0.8950946293054138\n",
      "claim: She was born in Leningrad, Soviet Union.\n",
      "aligned tokens: [11]\n",
      "UE score: -0.9861443665651616\n",
      "claim: The individual is from Petersburg, Russia.\n",
      "aligned tokens: [35, 36, 38]\n",
      "UE score: -0.9999847720222879\n",
      "claim: The individual is a renowned Russian singer.\n",
      "aligned tokens: [40, 41, 42, 43, 44, 45]\n",
      "UE score: -0.9540917110619055\n",
      "claim: The individual is an actress.\n",
      "aligned tokens: [40, 41, 47]\n",
      "UE score: -0.5311059161672468\n",
      "claim: The individual is a television personality.\n",
      "aligned tokens: [50, 51]\n",
      "UE score: -0.9979298951148988\n",
      "claim: She is often referred to as the \"Queen of Russian Song\".\n",
      "aligned tokens: [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]\n",
      "UE score: -0.477846375597142\n",
      "claim: She is one of the most popular figures in Russian entertainment.\n",
      "aligned tokens: [53, 54, 69, 70, 71, 72, 73, 76, 77, 78, 79]\n",
      "UE score: -0.5994490127058355\n",
      "claim: She is one of the most influential figures in Russian entertainment.\n",
      "aligned tokens: [53, 54, 69, 70, 71, 72, 75, 76, 77, 78, 79]\n",
      "UE score: -0.6021617351326098\n",
      "\n",
      "Output: Paul McCartney, born on June 18, 1942, in Liverpool, England, is a legendary musician, singer-songwriter, and bassist known for his influential role in the Beatles, one of the most successful and influential bands in the history of music. McCartney began his musical journey as a teenager, forming the Quarrymen with John Lennon in 1957. The band later evolved into the Beatles, with the\n",
      "claim: Paul McCartney was born on June 18, 1942.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 6, 7]\n",
      "UE score: -0.9820730108529162\n",
      "claim: He was born in Liverpool, England.\n",
      "aligned tokens: [0, 1, 2, 3, 5]\n",
      "UE score: -0.9982728627862665\n",
      "claim: He is a legendary musician.\n",
      "aligned tokens: [0, 1, 2, 3]\n",
      "UE score: -0.9999929044038958\n",
      "claim: He is a singer-songwriter.\n",
      "aligned tokens: [0, 1, 2, 3]\n",
      "UE score: -0.9999929044038958\n",
      "claim: He is a bassist.\n",
      "aligned tokens: [0, 1, 2, 3]\n",
      "UE score: -0.9999929044038958\n",
      "claim: He is known for his influential role in the Beatles.\n",
      "aligned tokens: [0, 1, 2, 3]\n",
      "UE score: -0.9999929044038958\n",
      "claim: McCartney began his musical journey as a teenager.\n",
      "aligned tokens: [61, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
      "UE score: -0.9557887908647504\n",
      "claim: McCartney formed the Quarrymen with John Lennon.\n",
      "aligned tokens: [61, 62, 63, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
      "UE score: -0.8485421311647052\n",
      "claim: He formed the Quarrymen with John Lennon in 1957.\n",
      "aligned tokens: [61, 62, 63, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82]\n",
      "UE score: -0.8470379207081941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "args_generate = {\"generation_config\" : generation_config,\n",
    "                 \"max_new_tokens\": 100}\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    encoded = tokenizer(batch, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    deps = {\"model_inputs\": encoded}\n",
    "    deps.update(calc_infer_llm(\n",
    "        deps, texts=batch, model=model_adapter, args_generate=args_generate))\n",
    "    deps.update({\"greedy_texts\" : tokenizer.batch_decode(deps['greedy_tokens'])})\n",
    "    deps.update(calc_claim_extractor(deps, texts=batch, model=model_adapter))\n",
    "    deps.update(calc_claim_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertianty_scores = estimator(deps)\n",
    "\n",
    "    for text, claims, ue_score in zip(deps[\"greedy_texts\"], deps['claims'], uncertianty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        \n",
    "        for claim, ue in zip(claims, ue_score):\n",
    "            print(\"claim:\", claim.claim_text)\n",
    "            print(\"aligned tokens:\", claim.aligned_tokens)\n",
    "            print(\"UE score:\", ue)\n",
    "\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
