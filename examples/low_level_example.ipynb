{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733b31d9",
   "metadata": {},
   "source": [
    "# Low-Level Examples \n",
    "Here we present low-level examples of integrating LM-Polygraph into LLM inference using HF library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025e26e-fd7f-44b6-88d7-5876439a5ab0",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7111f938-bc8c-4b82-82a1-fce490bc8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = \"cuda:0\"\n",
    "dataset_name = \"../workdir/data/triviaqa.csv\"\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "generation_config = GenerationConfig.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024e188",
   "metadata": {},
   "source": [
    "## Sequence-Level Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b10d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"How many fingers on a coala's foot?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who sang a song Yesterday?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Кто спел песню Кукла Колдуна?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate into French: 'I want a small cup of coffee'\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e515bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_polygraph.stat_calculators.infer_causal_lm_calculator import InferCausalLMCalculator\n",
    "from lm_polygraph.stat_calculators.greedy_alternatives_nli import GreedyAlternativesNLICalculator\n",
    "from lm_polygraph.estimators.claim_conditioned_probability import ClaimConditionedProbability\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "from lm_polygraph.model_adapters import WhiteboxModelBasic\n",
    "\n",
    "\n",
    "model_adapter = WhiteboxModelBasic(model, tokenizer, tokenizer_args={})\n",
    "\n",
    "calc_infer_llm = InferCausalLMCalculator(tokenize=False)\n",
    "nli_model = Deberta(device=device)\n",
    "nli_model.setup()\n",
    "calc_nli = GreedyAlternativesNLICalculator(nli_model=nli_model)\n",
    "\n",
    "estimator = ClaimConditionedProbability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec05354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: A koala's paws do not have an opposable thumb or any other digit that resembles a human finger. Instead, they have five non-opposable, rough pads on each of their two hind feet and four on\n",
      "Uncertainty score: -0.030883181827615604\n",
      "\n",
      "Output: The song \"Yesterday\" was written and performed by the English singer-songwriter Paul McCartney, but it was originally performed by The Beatles. The song was released as a single in the United Kingdom on June 18,\n",
      "Uncertainty score: -0.26628770133840346\n",
      "\n",
      "Output: I'm assuming you're asking who sang the Russian folk song \"Kukla Koldun,\" which is also known as \"The Doll of Koldun.\" This song is a traditional Russian folk tune, and there are many different\n",
      "Uncertainty score: -0.003979121489207858\n",
      "\n",
      "Output: In French, the sentence \"I want a small cup of coffee\" can be translated as \"Je veux une tasse petite de café\" or \"Je vais avoir une tasse de café petite\". Both translations convey the same\n",
      "Uncertainty score: -0.056271856615366156\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "args_generate = {\"generation_config\" : generation_config,\n",
    "                 \"max_new_tokens\": 50}\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    encoded = tokenizer(batch, padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    deps = {\"model_inputs\": encoded}\n",
    "    deps.update(calc_infer_llm(\n",
    "        deps, texts=batch, model=model_adapter, args_generate=args_generate))\n",
    "    deps.update(calc_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertainty_scores = estimator(deps)\n",
    "    generated_texts = tokenizer.batch_decode(deps['greedy_tokens'])\n",
    "    \n",
    "    for text, ue_score in zip(generated_texts, uncertainty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        print(\"Uncertainty score:\", ue_score)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0beb1",
   "metadata": {},
   "source": [
    "## Claim-Level Examples\n",
    "Here we split text into actomic claims and quantify uncertainty of individual claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c543214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me a bio of Albert Einstein.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Alla Pugacheva.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Paul McCartney.\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lm_polygraph.model_adapters import WhiteboxModelBasic\n",
    "from lm_polygraph.estimators import ClaimConditionedProbabilityClaim\n",
    "from lm_polygraph.stat_calculators import *\n",
    "from lm_polygraph.utils.openai_chat import OpenAIChat\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "\n",
    "\n",
    "model_adapter = WhiteboxModelBasic(model, tokenizer, tokenizer_args={})\n",
    "\n",
    "calc_infer_llm = InferCausalLMCalculator(tokenize=False)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your OpenAI API key>\"\n",
    "calc_claim_extractor = ClaimsExtractor(OpenAIChat(\"gpt-4o\"))\n",
    "\n",
    "calc_claim_nli = GreedyAlternativesNLICalculator(Deberta(device=device))\n",
    "\n",
    "estimator = ClaimConditionedProbabilityClaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b9fb7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Albert Einstein (March 14, 1879 – April 18, 1955) was a German-born theoretical physicist who is widely regarded as one of the most influential scientists in history. He is best known for developing the theory of general relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science. He is best known to the general public\n",
      "claim: Albert Einstein was born on March 14, 1879.\n",
      "aligned tokens: [0, 1, 3, 4, 6, 7, 10, 11, 12, 13]\n",
      "UE score: -0.92425569683011\n",
      "claim: Albert Einstein died on April 18, 1955.\n",
      "aligned tokens: [0, 1, 15, 17, 18, 21, 22, 23, 24]\n",
      "UE score: -0.9995946172894377\n",
      "claim: Albert Einstein was a German-born theoretical physicist.\n",
      "aligned tokens: [0, 1, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "UE score: -0.7058116064427322\n",
      "claim: Albert Einstein is widely regarded as one of the most influential scientists in history.\n",
      "aligned tokens: [0, 1, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "UE score: -0.7098147831163774\n",
      "claim: He is best known for developing the theory of general relativity.\n",
      "aligned tokens: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "UE score: -0.9574012785198653\n",
      "claim: The theory of general relativity is one of the two pillars of modern physics.\n",
      "aligned tokens: [55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
      "UE score: -0.9934803946274909\n",
      "claim: Quantum mechanics is the other pillar of modern physics.\n",
      "aligned tokens: [55, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76]\n",
      "UE score: -0.977371256256544\n",
      "claim: His work is known for its influence on the philosophy of science.\n",
      "aligned tokens: [78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "UE score: -0.9664649558820244\n",
      "claim: His work is also known for its influence on the philosophy of science.\n",
      "aligned tokens: [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "UE score: -0.9664590188774684\n",
      "\n",
      "Output: Alla Pugacheva, born on November 17, 1949, in Moscow, Russia, is a renowned Soviet and Russian singer, songwriter, actress, and television personality. She is often referred to as the \"Queen of Russian Song\" and is one of the most popular and influential figures in Russian entertainment.\n",
      "\n",
      "Pugacheva's musical career began in the late 1960s when she was a student at the Moscow State\n",
      "claim: Alla Pugacheva was born on November 17, 1949.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 15, 16, 17, 18]\n",
      "UE score: -0.48403315566692684\n",
      "claim: Alla Pugacheva was born in Moscow, Russia.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 7, 20, 21, 23]\n",
      "UE score: -0.5837469427526598\n",
      "claim: Alla Pugacheva is a renowned Soviet singer.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 25, 26, 27, 28, 29, 32]\n",
      "UE score: -0.7978319359848641\n",
      "claim: Alla Pugacheva is a renowned Russian singer.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 25, 26, 27, 28, 31, 32]\n",
      "UE score: -0.8097058010117294\n",
      "claim: Alla Pugacheva is a songwriter.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 25, 26, 34, 35]\n",
      "UE score: -0.46212707703781636\n",
      "claim: Alla Pugacheva is a television personality.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 25, 26, 40, 41]\n",
      "UE score: -0.8194309642839227\n",
      "claim: She is often referred to as the \"Queen of Russian Song.\"\n",
      "aligned tokens: [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56]\n",
      "UE score: -0.6176558415515074\n",
      "claim: She is one of the most popular figures in Russian entertainment.\n",
      "aligned tokens: [43, 44, 59, 60, 61, 62, 63, 66, 67, 68, 69]\n",
      "UE score: -0.8376165103307378\n",
      "claim: She is one of the most influential figures in Russian entertainment.\n",
      "aligned tokens: [43, 44, 59, 60, 61, 62, 65, 66, 67, 68, 69]\n",
      "UE score: -0.8432842497811802\n",
      "\n",
      "Output: Paul McCartney, born on June 18, 1942, in Liverpool, England, is a legendary figure in the music industry as a singer, songwriter, and bassist known for his influential role in the iconic band, The Beatles. McCartney began his music career as a quartet with John Lennon, George Harrison, and Ringo Starr, forming one of the most successful and influential bands in history.\n",
      "\n",
      "McCartney'\n",
      "claim: Paul McCartney was born on June 18, 1942.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 6, 7, 9, 10, 13, 14, 15, 16]\n",
      "UE score: -0.8764688731701741\n",
      "claim: Paul McCartney was born in Liverpool, England.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 18, 19, 21]\n",
      "UE score: -0.9991916206956636\n",
      "claim: Paul McCartney is a legendary figure in the music industry.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "UE score: -0.24785145410490095\n",
      "claim: Paul McCartney is a singer.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 24, 33]\n",
      "UE score: -0.9825582918199313\n",
      "claim: Paul McCartney is a songwriter.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 35, 36]\n",
      "UE score: -0.9958032211861809\n",
      "claim: Paul McCartney is a bassist.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 24, 39, 40]\n",
      "UE score: -0.8149675913489247\n",
      "claim: Paul McCartney is known for his influential role in The Beatles.\n",
      "aligned tokens: [0, 1, 2, 3, 41, 42, 43, 44, 45, 46, 52, 53, 54]\n",
      "UE score: -0.9720732838785745\n",
      "claim: The Beatles is an iconic band.\n",
      "aligned tokens: [48, 49, 50, 52, 53, 54]\n",
      "UE score: -0.5556277372832952\n",
      "claim: McCartney began his music career as a quartet with John Lennon, George Harrison, and Ringo Starr.\n",
      "aligned tokens: [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80]\n",
      "UE score: -0.7537651551193327\n",
      "claim: McCartney, John Lennon, George Harrison, and Ringo Starr formed one of the most successful and influential bands in history.\n",
      "aligned tokens: [56, 57, 58, 68, 69, 70, 71, 73, 74, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92]\n",
      "UE score: -0.44487918753102684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "args_generate = {\"generation_config\" : generation_config,\n",
    "                 \"max_new_tokens\": 100}\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    encoded = tokenizer(batch, padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    deps = {\"model_inputs\": encoded}\n",
    "    deps.update(calc_infer_llm(\n",
    "        deps, texts=batch, model=model_adapter, args_generate=args_generate))\n",
    "    deps.update({\"greedy_texts\" : tokenizer.batch_decode(deps['greedy_tokens'])})\n",
    "    deps.update(calc_claim_extractor(deps, texts=batch, model=model_adapter))\n",
    "    deps.update(calc_claim_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertainty_scores = estimator(deps)\n",
    "\n",
    "    for text, claims, ue_score in zip(deps[\"greedy_texts\"], deps['claims'], uncertainty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        \n",
    "        for claim, ue in zip(claims, ue_score):\n",
    "            print(\"claim:\", claim.claim_text)\n",
    "            print(\"aligned tokens:\", claim.aligned_token_ids)\n",
    "            print(\"UE score:\", ue)\n",
    "\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
