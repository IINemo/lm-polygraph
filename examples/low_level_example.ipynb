{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733b31d9",
   "metadata": {},
   "source": [
    "# Low-Level Examples \n",
    "Here we present low-level examples of integrating LM-Polygraph into LLM inference using HF library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025e26e-fd7f-44b6-88d7-5876439a5ab0",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418fa8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7111f938-bc8c-4b82-82a1-fce490bc8e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = \"cuda:0\"\n",
    "dataset_name = \"LM-Polygraph/triviaqa\"\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ec17dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=device,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024e188",
   "metadata": {},
   "source": [
    "## Sequence-Level Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b10d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"How many fingers on a coala's foot?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who sang a song Yesterday?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Кто спел песню Кукла Колдуна?\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Translate into French: 'I want a small cup of coffee'\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e515bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from lm_polygraph.stat_calculators import GreedyProbsCalculator, GreedyAlternativesNLICalculator\n",
    "from lm_polygraph.estimators.claim_conditioned_probability import ClaimConditionedProbability\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "from lm_polygraph.utils.generation_parameters import GenerationParameters\n",
    "from lm_polygraph.model_adapters import WhiteboxModel\n",
    "\n",
    "\n",
    "max_new_tokens = 100\n",
    "generation_params = GenerationParameters()\n",
    "generation_params.temperature = 0.9\n",
    "generation_params.do_sample = True\n",
    "\n",
    "model_adapter = WhiteboxModel(model, tokenizer, generation_parameters=generation_params)\n",
    "\n",
    "calc_greedy_probs = GreedyProbsCalculator()\n",
    "nli_model = Deberta(device=device)\n",
    "nli_model.setup()\n",
    "calc_nli = GreedyAlternativesNLICalculator(nli_model=nli_model)\n",
    "\n",
    "estimator = ClaimConditionedProbability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec05354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemshelmanov/conda/lib/python3.12/site-packages/bitsandbytes/nn/modules.py:463: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n",
      "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: A koala's paws do not have an opposable thumb or any fingers like humans do. Instead, they have five non-opposable, roughly similar digits on each of their forepaws and four on their hind paws, for a total of 20 digits on both their front and hind paws. However, since fingers in the human sense do not exist on a koala's paws, it's not an accurate question to ask.</s>\n",
      "Uncertainty score: -1.2142750309824153e-06\n",
      "\n",
      "Output: The song \"Yesterday\" was written and performed by Paul McCartney, but credit is often given to The Beatles as a group since the song was released under their name. However, McCartney performs the solo version on the recording, and the quartet only provided the instrumental background on the original 1965 release. To clarify, Paul McCartney sang \"Yesterday.\"</s>\n",
      "Uncertainty score: -3.7164147931175543e-07\n",
      "\n",
      "Output: I'm an artificial intelligence and don't have the ability to sing or listen to music. However, I can help you find information about the performer of the song \"Kukla Koldun\" (Дульфыз Кулап, also known as \"Puppele Doll\" in English).\n",
      "\n",
      "Kukla Koldun is actually the stage name of Aleksandra Pavlovna Volchkova (Александра Павловна\n",
      "Uncertainty score: -7.125606279480632e-09\n",
      "\n",
      "Output: Je veux une tasse petite de café.\n",
      "\n",
      "In this sentence, \"Je\" is \"I\" in French, \"veux\" is \"want\", \"une\" is \"a\", \"tasse\" is \"cup\", \"petite\" is \"small\" and \"de\" is \"of\" or \"a\". So, the entire sentence means \"I want a small cup of coffee\".</s>\n",
      "Uncertainty score: -0.0006877919288538601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    deps = dict()\n",
    "    deps.update(calc_greedy_probs(\n",
    "        deps, texts=batch, model=model_adapter, max_new_tokens=max_new_tokens))\n",
    "    deps.update(calc_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertainty_scores = estimator(deps)\n",
    "    generated_texts = tokenizer.batch_decode(deps['greedy_tokens'])\n",
    "    \n",
    "    for text, ue_score in zip(generated_texts, uncertainty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        print(\"Uncertainty score:\", ue_score)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0beb1",
   "metadata": {},
   "source": [
    "## Claim-Level Examples\n",
    "Here we split text into actomic claims and quantify uncertainty of individual claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c543214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me a bio of Albert Einstein.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Alla Pugacheva.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Paul McCartney.\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa13a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from lm_polygraph.model_adapters import WhiteboxModelBasic\n",
    "from lm_polygraph.estimators import ClaimConditionedProbabilityClaim\n",
    "from lm_polygraph.stat_calculators import *\n",
    "from lm_polygraph.utils.openai_chat import OpenAIChat\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "\n",
    "\n",
    "max_new_tokens = 100\n",
    "generation_params = GenerationParameters()\n",
    "generation_params.temperature = 0.9\n",
    "generation_params.do_sample = True\n",
    "\n",
    "model_adapter = WhiteboxModel(model, tokenizer, generation_parameters=generation_params)\n",
    "\n",
    "calc_greedy_probs = GreedyProbsCalculator()\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<Your OpenAI API key>\"\n",
    "calc_claim_extractor = ClaimsExtractor(OpenAIChat(\"gpt-4o\"))\n",
    "calc_claim_nli = GreedyAlternativesNLICalculator(Deberta(device=device))\n",
    "\n",
    "estimator = ClaimConditionedProbabilityClaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b9fb7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Albert Einstein (March 14, 1879 – April 18, 1955) was a German-born theoretical physicist who is widely regarded as one of the most influential scientists in history. He is best known for developing the theory of general relativity, one of the two pillars of modern physics (alongside quantum mechanics). His work is also known for its influence on the philosophy of science.\n",
      "\n",
      "Einstein was born in\n",
      "claim: Albert Einstein was born on March 14, 1879.\n",
      "aligned tokens: [0, 1, 3, 4, 6, 7, 10, 11, 12, 13]\n",
      "UE score: -0.7957917064115393\n",
      "claim: Albert Einstein died on April 18, 1955.\n",
      "aligned tokens: [0, 1, 15, 17, 18, 21, 22, 23, 24]\n",
      "UE score: -0.9997172893343415\n",
      "claim: Albert Einstein was a German-born theoretical physicist.\n",
      "aligned tokens: [0, 1, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "UE score: -0.45843554806918824\n",
      "claim: Albert Einstein is widely regarded as one of the most influential scientists in history.\n",
      "aligned tokens: [0, 1, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "UE score: -0.619605820088794\n",
      "claim: He is best known for developing the theory of general relativity.\n",
      "aligned tokens: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "UE score: -0.9587778970203076\n",
      "claim: The theory of general relativity is one of the two pillars of modern physics.\n",
      "aligned tokens: [55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70]\n",
      "UE score: -0.993359419217267\n",
      "claim: Quantum mechanics is the other pillar of modern physics.\n",
      "aligned tokens: [55, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76]\n",
      "UE score: -0.9712799402916199\n",
      "claim: His work is known for its influence on the philosophy of science.\n",
      "aligned tokens: [78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "UE score: -0.9609519397257412\n",
      "claim: His work is also known for its influence on the philosophy of science.\n",
      "aligned tokens: [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90]\n",
      "UE score: -0.9609499777643757\n",
      "\n",
      "Output: Alla Pugacheva, born Alla Sergeevna Pugacheva on November 17, 1949, is a Russian singer, songwriter, and actress, widely regarded as the \"Queen of Russian Song\" and one of the most influential and popular performers in Russian show business. Born in Moscow, Pugacheva grew up in a musical family and showed an early aptitude for music. She began her career in the 1960\n",
      "claim: Alla Pugacheva was born Alla Sergeevna Pugacheva.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "UE score: -0.16014216696545897\n",
      "claim: Alla Pugacheva was born on November 17, 1949.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 7, 17, 18, 20, 21, 24, 25, 26, 27]\n",
      "UE score: -0.3077009944068872\n",
      "claim: Alla Pugacheva is a Russian singer.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 29, 30, 31, 32]\n",
      "UE score: -0.31078871677758574\n",
      "claim: Alla Pugacheva is a songwriter.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 29, 30, 34, 35]\n",
      "UE score: -0.7566179431793028\n",
      "claim: Alla Pugacheva is widely regarded as the \"Queen of Russian Song.\"\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n",
      "UE score: -0.4244621225083738\n",
      "claim: Alla Pugacheva is one of the most influential performers in Russian show business.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 29, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 64]\n",
      "UE score: -0.7493259947137044\n",
      "claim: Alla Pugacheva is one of the most popular performers in Russian show business.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 29, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64]\n",
      "UE score: -0.6932055951832875\n",
      "claim: Pugacheva was born in Moscow.\n",
      "aligned tokens: [66, 67, 68, 70, 71, 72, 73]\n",
      "UE score: -0.011466662226961438\n",
      "claim: Pugacheva grew up in a musical family.\n",
      "aligned tokens: [70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "UE score: -0.2602126644556673\n",
      "claim: Pugacheva showed an early aptitude for music.\n",
      "aligned tokens: [70, 71, 72, 73, 81, 82, 83, 84, 85, 86, 87]\n",
      "UE score: -0.3065021153483495\n",
      "\n",
      "Output: Paul McCartney, born on June 18, 1942, in Liverpool, England, is a legendary figure in the music industry, renowned as the bass guitarist, singer, and primary songwriter for the iconic band The Beatles. McCartney is considered one of the most influential figures in music history, with a career that spans over six decades.\n",
      "\n",
      "McCartney's music journey began in his hometown of Liverpool, where he\n",
      "claim: Paul McCartney was born on June 18, 1942.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 6, 7, 9, 10, 13, 14, 15, 16]\n",
      "UE score: -0.8811129144644859\n",
      "claim: Paul McCartney was born in Liverpool, England.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 18, 19, 21]\n",
      "UE score: -0.9991930409100092\n",
      "claim: Paul McCartney is a legendary figure in the music industry.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 24, 25, 26, 27, 28, 29, 30]\n",
      "UE score: -0.24644870278611836\n",
      "claim: Paul McCartney is renowned as the bass guitarist for The Beatles.\n",
      "aligned tokens: [0, 1, 2, 3, 32, 33, 34, 35, 36, 37, 38, 46, 51, 52, 53]\n",
      "UE score: -0.9904875309308436\n",
      "claim: Paul McCartney is renowned as a singer for The Beatles.\n",
      "aligned tokens: [0, 1, 2, 3, 32, 33, 40, 51, 52, 53]\n",
      "UE score: -0.9979272490661234\n",
      "claim: Paul McCartney is renowned as the primary songwriter for The Beatles.\n",
      "aligned tokens: [0, 1, 2, 3, 32, 33, 43, 44, 45, 51, 52, 53]\n",
      "UE score: -0.8913385292163033\n",
      "claim: The Beatles is an iconic band.\n",
      "aligned tokens: [48, 49, 50, 51, 52, 53]\n",
      "UE score: -0.5236447761608546\n",
      "claim: McCartney is considered one of the most influential figures in music history.\n",
      "aligned tokens: [55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68]\n",
      "UE score: -0.01861964710860395\n",
      "claim: McCartney has a career that spans over six decades.\n",
      "aligned tokens: [55, 56, 57, 70, 71, 72, 73, 74, 75, 76, 77, 78]\n",
      "UE score: -0.24593377267400882\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    encoded = tokenizer(batch, padding=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    deps = {\"model_inputs\": encoded}\n",
    "    deps.update(calc_greedy_probs(\n",
    "        deps, texts=batch, model=model_adapter, max_new_tokens=max_new_tokens))\n",
    "    deps.update({\"greedy_texts\" : tokenizer.batch_decode(deps['greedy_tokens'])})\n",
    "    deps.update(calc_claim_extractor(deps, texts=batch, model=model_adapter))\n",
    "    deps.update(calc_claim_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertainty_scores = estimator(deps)\n",
    "\n",
    "    for text, claims, ue_score in zip(deps[\"greedy_texts\"], deps['claims'], uncertainty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        \n",
    "        for claim, ue in zip(claims, ue_score):\n",
    "            print(\"claim:\", claim.claim_text)\n",
    "            print(\"aligned tokens:\", claim.aligned_token_ids)\n",
    "            print(\"UE score:\", ue)\n",
    "\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
