{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6958a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_polygraph.utils.model import WhiteboxModel, BlackboxModel\n",
    "from lm_polygraph.utils.manager import estimate_uncertainty\n",
    "from lm_polygraph.estimators import MaximumTokenProbability, LexicalSimilarity, SemanticEntropy, PointwiseMutualInformation, EigValLaplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7a7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WhiteboxModel.from_pretrained(\n",
    "    'bigscience/bloomz-560m',\n",
    "    device='cpu',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247f5d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergeypetrakov/Documents/Documents/hf_connect/hf_connect/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n",
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=[' President of the United States'], generation_tokens=[[14032, 461, 368, 8097, 10650, 2]], uncertainty=[-0.24327608942985535, -0.924824595451355, -0.9097719788551331, -0.995514988899231, -0.9928673505783081])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumTokenProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='Who is George Bush?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8292b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=[' President of the United States'], generation_tokens=[[14032, 461, 368, 8097, 10650, 2]], uncertainty=[-0.9176470588235295])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LexicalSimilarity('rougeL')\n",
    "estimate_uncertainty(model, estimator, input_text='Who is George Bush?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a906db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=[' President of the United States'], generation_tokens=[[14032, 461, 368, 8097, 10650, 2]], uncertainty=[3.0035024890214275])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = SemanticEntropy()\n",
    "estimate_uncertainty(model, estimator, input_text='Who is George Bush?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90f3c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=[' play with her dolls. She was a little girl who was very clever and had a great imagination.'], generation_tokens=[[7229, 1002, 3809, 17486, 86, 17, 15114, 1620, 267, 10512, 27566, 5268, 1620, 5636, 149014, 530, 3866, 267, 10087, 113763, 17, 2]], uncertainty=[2.019789218902588, -5.537353157997131, -4.312102556228638, -5.030910968780518, -2.7699881196022034, -10.396235346794128, -9.28441572189331, -11.279396176338196, -8.391041040420532, -7.909592628479004, -4.460748910903931, -5.949978590011597, -7.363903284072876, -8.148085594177246, -2.7360548973083496, -8.350634574890137, -5.361073970794678, -5.55866664648056, -6.428493142127991, -7.301618158817291, -10.471122086048126])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = PointwiseMutualInformation()\n",
    "estimate_uncertainty(model, estimator, input_text='Once upon a time there was a little girl who liked to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc03fd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=[' President of the United States'], generation_tokens=[[14032, 461, 368, 8097, 10650, 2]], uncertainty=[-0.926315789473684])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ue_method = LexicalSimilarity()\n",
    "input_text = \"Who is George Bush?\"\n",
    "estimate_uncertainty(model, ue_method, input_text=input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb84386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated answers: ['Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.', 'Albert Einstein died on April 18, 1955.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=['Albert Einstein died on April 18, 1955.'], generation_tokens=None, uncertainty=[1.0022274826855433])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BlackboxModel(\n",
    "    'YOUR_OPENAI_TOKEN',\n",
    "    'gpt-3.5-turbo'\n",
    ")\n",
    "estimator = EigValLaplacian(verbose=True)\n",
    "estimate_uncertainty(model, estimator, input_text='When did Albert Einstein die?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b63635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model google/t5-large-ssm-nqo is currently loading. Estimated time: 118.04 sec.\n",
      "Model google/t5-large-ssm-nqo is currently loading. Estimated time: 112.57 sec.\n",
      "Model google/t5-large-ssm-nqo is currently loading. Estimated time: 107.14 sec.\n",
      "Model google/t5-large-ssm-nqo is currently loading. Estimated time: 101.69 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=['former United States President'], generation_tokens=None, uncertainty=[-0.05747126436781609])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_TOKEN = 'YOUR_API_TOKEN'\n",
    "# for example let's take google/t5-small-ssm-nq model\n",
    "MODEL_ID = 'google/t5-large-ssm-nqo'\n",
    "\n",
    "model = BlackboxModel.from_huggingface(hf_api_token=API_TOKEN, hf_model_id=MODEL_ID, openai_api_key = None, openai_model_path = None)\n",
    "ue_method = LexicalSimilarity()\n",
    "input_text = \"Who is George Bush?\"\n",
    "estimate_uncertainty(model, ue_method, input_text=input_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ec1991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: no normalization bounds found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(generation_text=['Who is George Bush? President of the United States'], generation_tokens=None, uncertainty=[-0.044897959183673466])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for example let's take bigscience/bloomz-560m model\n",
    "MODEL_ID = 'bigscience/bloomz-560m'\n",
    "\n",
    "model = BlackboxModel.from_huggingface(hf_api_token=API_TOKEN, hf_model_id=MODEL_ID, openai_api_key = None, openai_model_path = None)\n",
    "ue_method = LexicalSimilarity()\n",
    "input_text = \"Who is George Bush?\"\n",
    "estimate_uncertainty(model, ue_method, input_text=input_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81173a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
