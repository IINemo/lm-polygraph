{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0acb062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b1d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "device = \"cuda:0\"\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6560b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b7ae864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54da1b397dec4c4485f9852264c57213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c9801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Tell me a bio of Albert Einstein.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Alla Pugacheva.\"\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a bio of Paul McCartney\"\n",
    "        }\n",
    "    ]\n",
    "]\n",
    "\n",
    "chat_messages = [tokenizer.apply_chat_template(m, tokenize=False) for m in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2086aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/artemshelmanov/workspace/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from lm_polygraph.model_adapters import WhiteboxModelBasic\n",
    "from lm_polygraph.estimators import ClaimConditionedProbabilityClaim\n",
    "from lm_polygraph.stat_calculators import *\n",
    "from lm_polygraph.utils.openai_chat import OpenAIChat\n",
    "from lm_polygraph.utils.deberta import Deberta\n",
    "\n",
    "\n",
    "model_adapter = WhiteboxModelBasic(model, tokenizer)\n",
    "\n",
    "calc_infer_llm = InferCausalLMCalculator(tokenize=False)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "calc_claim_extractor = ClaimsExtractor(OpenAIChat(\"gpt-4\"))\n",
    "\n",
    "calc_claim_nli = GreedyAlternativesNLICalculator(Deberta())\n",
    "\n",
    "estimator = ClaimConditionedProbabilityClaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d705c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artemshelmanov/workspace/conda/lib/python3.11/site-packages/transformers/generation/utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: Albert Einstein (March 14, 1879 – April 18, 1955) was a German-born theoretical physicist who is widely recognized as one of the most influential scientists in history. He is best known for developing the theory of relativity, which revolutionized our understanding of space, time, and gravity.\n",
      "\n",
      "Einstein was born in Ulm, Württemberg, Germany, to Hermann and Pauline Einstein\n",
      "claim: Albert Einstein was born on March 14, 1879.\n",
      "aligned tokens: [0, 1, 3, 4, 6, 7, 10, 11, 12, 13]\n",
      "UE score: -0.6843191534332486\n",
      "claim: Albert Einstein died on April 18, 1955.\n",
      "aligned tokens: [0, 1, 15, 17, 18, 21, 22, 23, 24]\n",
      "UE score: -0.9999582851741198\n",
      "claim: Albert Einstein was a German-born theoretical physicist.\n",
      "aligned tokens: [0, 1, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
      "UE score: -0.6499102674047008\n",
      "claim: Albert Einstein is widely recognized as one of the most influential scientists in history.\n",
      "aligned tokens: [0, 1, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "UE score: -0.8114264568106548\n",
      "claim: He is best known for developing the theory of relativity.\n",
      "aligned tokens: [49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "UE score: -0.9496401434670132\n",
      "claim: The theory of relativity revolutionized our understanding of space.\n",
      "aligned tokens: [54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67]\n",
      "UE score: -0.7474665738063865\n",
      "claim: The theory of relativity revolutionized our understanding of time.\n",
      "aligned tokens: [54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 69]\n",
      "UE score: -0.7488839618600632\n",
      "claim: The theory of relativity revolutionized our understanding of gravity.\n",
      "aligned tokens: [54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 72]\n",
      "UE score: -0.7488083266226561\n",
      "\n",
      "Output: Alla Borisovna Pugacheva, born on September 2, 1949, in Leningrad, Soviet Union (now St. Petersburg, Russia), is a renowned Russian singer, actress, and television personality. She is often referred to as the \"Queen of Russian Song\" and is one of the most popular and influential figures in Russian entertainment.\n",
      "\n",
      "Pugacheva began her career in the late 1960s, performing\n",
      "claim: Alla Borisovna Pugacheva was born.\n",
      "aligned tokens: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11]\n",
      "UE score: -0.7597518591512163\n",
      "claim: She was born on September 2, 1949.\n",
      "aligned tokens: [11, 12, 13, 15, 18, 19, 20, 21]\n",
      "UE score: -0.5163660568071037\n",
      "claim: She was born in Leningrad, Soviet Union.\n",
      "aligned tokens: [11, 23, 24, 25, 26, 28, 29]\n",
      "UE score: -0.45473732339180756\n",
      "claim: The place of her birth is now known as St. Petersburg, Russia.\n",
      "aligned tokens: [24, 25, 26, 28, 29, 30, 31, 32]\n",
      "UE score: -0.37515529367132605\n",
      "claim: The person is from Petersburg, Russia.\n",
      "aligned tokens: [34, 35, 37]\n",
      "UE score: -0.9999865569561794\n",
      "claim: The person is a renowned Russian singer.\n",
      "aligned tokens: [39, 40, 41, 42, 43, 44]\n",
      "UE score: -0.9607021194469028\n",
      "claim: The person is an actress.\n",
      "aligned tokens: [39, 40, 46]\n",
      "UE score: -0.6112778785397588\n",
      "claim: The person is a television personality.\n",
      "aligned tokens: [49, 50]\n",
      "UE score: -0.9979080428152782\n",
      "claim: She is one of the most popular figures in Russian entertainment.\n",
      "aligned tokens: [52, 53, 68, 69, 70, 71, 72, 75, 76, 77, 78]\n",
      "UE score: -0.6226713515186142\n",
      "claim: She is one of the most influential figures in Russian entertainment.\n",
      "aligned tokens: [52, 53, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78]\n",
      "UE score: -0.6205116666107992\n",
      "\n",
      "Output: Paul McCartney, born on June 18, 1942, in Liverpool, England, is a legendary musician, singer-songwriter, and composer known for his influential role in the Beatles, one of the most successful and influential bands in the history of music. McCartney began his music career as a teenager when he and John Lennon formed the Quarrymen, which later evolved into the Beatles.\n",
      "\n",
      "As a member of the Beatles\n",
      "claim: Paul McCartney was born on June 18, 1942.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 6, 7, 9, 10, 13, 14, 15, 16]\n",
      "UE score: -0.9730357433434005\n",
      "claim: Paul McCartney was born in Liverpool, England.\n",
      "aligned tokens: [0, 1, 2, 3, 5, 18, 19, 21]\n",
      "UE score: -0.9994180859766282\n",
      "claim: Paul McCartney is a legendary musician.\n",
      "aligned tokens: [0, 1, 2, 3, 23, 24, 25, 26]\n",
      "UE score: -0.7631477010475979\n",
      "claim: Paul McCartney is a singer-songwriter.\n",
      "aligned tokens: [0, 1, 2, 3, 28, 29, 30, 31, 32]\n",
      "UE score: -0.8638470122714933\n",
      "claim: Paul McCartney is a composer.\n",
      "aligned tokens: [0, 1, 2, 3, 35]\n",
      "UE score: -0.508961780969143\n",
      "claim: Paul McCartney is known for his influential role in the Beatles.\n",
      "aligned tokens: [0, 1, 2, 3, 36, 37, 38, 39, 40, 41, 42, 43, 44]\n",
      "UE score: -0.9324531151470425\n",
      "claim: The Beatles is one of the most successful and influential bands in the history of music.\n",
      "aligned tokens: [42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58]\n",
      "UE score: -0.4285065378989142\n",
      "claim: McCartney began his music career as a teenager.\n",
      "aligned tokens: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "UE score: -0.41578463989462083\n",
      "claim: He and John Lennon formed the Quarrymen.\n",
      "aligned tokens: [71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]\n",
      "UE score: -0.5858981354846385\n",
      "claim: The Quarrymen later evolved into the Beatles.\n",
      "aligned tokens: [79, 80, 81, 84, 85, 86, 87, 88, 89]\n",
      "UE score: -0.9959167946121104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "args_generate = {\"generation_config\" : generation_config,\n",
    "                 \"max_new_tokens\": 100}\n",
    "\n",
    "data_loader = DataLoader(chat_messages, batch_size=batch_size, shuffle=False, collate_fn=lambda x: x)\n",
    "for batch in data_loader:\n",
    "    encoded = tokenizer(batch, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "    deps = {\"model_inputs\": encoded}\n",
    "    deps.update(calc_infer_llm(\n",
    "        deps, texts=batch, model=model_adapter, args_generate=args_generate))\n",
    "    deps.update({\"greedy_texts\" : tokenizer.batch_decode(deps['greedy_tokens'])})\n",
    "    deps.update(calc_claim_extractor(deps, texts=batch, model=model_adapter))\n",
    "    deps.update(calc_claim_nli(deps, texts=None, model=model_adapter))\n",
    "\n",
    "    uncertianty_scores = estimator(deps)\n",
    "\n",
    "    for text, claims, ue_score in zip(deps[\"greedy_texts\"], deps['claims'], uncertianty_scores):\n",
    "        print(\"Output:\", text)\n",
    "        \n",
    "        for claim, ue in zip(claims, ue_score):\n",
    "            print(\"claim:\", claim.claim_text)\n",
    "            print(\"aligned tokens:\", claim.aligned_token_ids)\n",
    "            print(\"UE score:\", ue)\n",
    "\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
