{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0404fe31",
   "metadata": {},
   "source": [
    "# Basic Examples of LM-Polygraph Usage\n",
    "\n",
    "This notebook contains basic examples of obtaining uncertainty scores for LLMs along with generations using a high-level API function:\n",
    "\n",
    "```estimate_uncertainty(model, estimator, input_text)```. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d24995",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f565f3-5542-451f-ba22-db777274166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that you have installed lm-polygraph: \n",
    "# pip install git+https://github.com/artemshelmanov/lm-polygraph.git\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b6bc2",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6958a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from lm_polygraph.utils.model import WhiteboxModel, BlackboxModel\n",
    "from lm_polygraph import estimate_uncertainty\n",
    "from lm_polygraph.estimators import MaximumTokenProbability, MaximumSequenceProbability, SemanticEntropy, EigValLaplacian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459f454",
   "metadata": {},
   "source": [
    "## UQ for Whitebox LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dc0e6-804f-490e-9b77-4f5b3cb0ad64",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e7a7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='cpu',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = WhiteboxModel(base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043671a-939f-421b-b06b-24abf557fdc9",
   "metadata": {},
   "source": [
    "### Sequence-level UQ for a Whitebox LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687dd788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=3.913156032562256, input_text='How many floors are in the Empire State Building?', generation_text='The Empire State Building has 105 floors.', generation_tokens=[785, 20448, 3234, 16858, 702, 220, 16, 15, 20, 25945, 13], model_path=None, estimator='MaximumSequenceProbability')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumSequenceProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='How many floors are in the Empire State Building?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061056eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=61.402503967285156, input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='MaximumSequenceProbability')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumSequenceProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a906db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=99.17972927011878, input_text='How many floors are in the Empire State Building?', generation_text='The Empire State Building has 105 floors.', generation_tokens=[785, 20448, 3234, 16858, 702, 220, 16, 15, 20, 25945, 13], model_path=None, estimator='SemanticEntropy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It takes 2 mins to run the example.\n",
    "\n",
    "estimator = SemanticEntropy()\n",
    "estimate_uncertainty(model, estimator, input_text='How many floors are in the Empire State Building?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=115.85714697341697, input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='SemanticEntropy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It takes 2 mins to run the example.\n",
    "\n",
    "estimator = SemanticEntropy()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18648a-b1c7-4089-832e-84e17be8b203",
   "metadata": {},
   "source": [
    "### Token-level UQ for Whitebox LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247f5d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=array([-0.5199645 , -0.7773075 , -0.9111757 , -0.4642391 , -0.7312121 ,\n",
       "       -0.96189463, -0.27488053, -0.11001918, -0.72922415, -0.43932858,\n",
       "       -0.99928606, -0.5605216 , -0.23990016, -0.7537944 , -0.24525657,\n",
       "       -0.6493522 , -0.99975866, -0.51964307, -0.8791548 , -0.21423468,\n",
       "       -0.35266286, -0.47724998, -0.45849365, -0.38198572, -0.8100885 ,\n",
       "       -0.6418665 , -0.7694248 , -0.30586314, -0.99927765, -0.9042026 ,\n",
       "       -0.87831134, -0.9398997 , -0.52133787, -0.5053506 , -0.9973978 ,\n",
       "       -0.67501503, -0.49679896, -0.7429459 , -0.35794568, -0.10462207,\n",
       "       -0.16433331, -0.5641733 , -0.80949354, -0.7477126 , -0.21802613,\n",
       "       -0.12109879, -0.6510552 , -0.2837354 , -0.2947866 , -0.98860633,\n",
       "       -0.5185005 , -0.1949296 , -0.51526326, -0.9765778 , -0.7364911 ,\n",
       "       -0.442843  , -0.2552529 , -0.9931718 , -0.49535578, -0.17133856,\n",
       "       -0.2405345 , -0.5826117 , -0.89956623, -0.22676547, -0.9783974 ,\n",
       "       -0.7804185 , -0.30011195, -0.541584  , -0.28006086, -0.5264636 ,\n",
       "       -0.96796274, -0.999999  , -0.5594297 , -0.44038415, -0.5604101 ,\n",
       "       -0.16485405, -0.99984914, -0.9997313 , -0.99999946, -0.23093723,\n",
       "       -0.29331768, -0.9013605 , -0.4138443 , -0.5036779 , -0.9412839 ,\n",
       "       -0.11232074, -0.9069531 ], dtype=float32), input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='MaximumTokenProbability')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumTokenProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c7940d-9f83-4872-a0e3-d2e9a83d8a9e",
   "metadata": {},
   "source": [
    "## UQ for a Blackbox LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75815ea3",
   "metadata": {},
   "source": [
    "### Sequence-Level UQ for LLM deployed via OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9c577d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_KEY = '<Your OpenAI key>'\n",
    "model = BlackboxModel(\n",
    "    OPENAI_KEY,\n",
    "    'gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5fb84386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=1.0005499646067637, input_text='How many floors are in the Empire State Building?', generation_text='The Empire State Building has 102 floors.', generation_tokens=None, model_path='gpt-4o-mini', estimator='EigValLaplacian_NLI_score_entail')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = EigValLaplacian(verbose=True)\n",
    "estimate_uncertainty(model, estimator, input_text='How many floors are in the Empire State Building?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5269e085",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=1.7574554956017185, input_text='What has a head and a tail but no body?', generation_text='The answer to the riddle \"What has a head and a tail but no body?\" is a coin. It has a \"head\" side and a \"tail\" side, but no physical body.', generation_tokens=None, model_path='gpt-4o-mini', estimator='EigValLaplacian_NLI_score_entail')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = EigValLaplacian(verbose=True)\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5be881",
   "metadata": {},
   "source": [
    "### Sequence-Level UQ for LLM deployed via HuggingFace API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "148d3385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without the HuggingFace pro account HF API might return error.\n",
    "\n",
    "HUGGINGFACE_API_TOKEN = '<Your HuggingFace API token>'\n",
    "MODEL_ID = 'meta-llama/Llama-3.3-70B-Instruct'\n",
    "model = BlackboxModel.from_huggingface(hf_api_token=HUGGINGFACE_API_TOKEN, hf_model_id=MODEL_ID, openai_api_key=None, openai_model_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5b63635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=0.7366183713303993, input_text='How many floors are in the Empire State Building? Just answer the question.', generation_text=\"How many floors are in the Empire State Building? Just answer the question. 102. \\n\\nNow if you need more information: The Empire State Building is an iconic 102-story skyscraper located in Midtown Manhattan, New York City. It was completed in 1931 and held the title of the world's tallest building for nearly 40 years. In addition to its impressive height, the building is also notable for its Art Deco design and historic significance, having been a symbol of American ingenuity and progress during a time of great economic and social change. Today, the Empire State Building remains a popular tourist destination and a prominent feature of the New York City skyline. \\n\\nAnd if you're a trivia buff: The Empire State Building has a total of 6,514 windows, 60,000 tons of steel, and 10 million bricks. It stands at a height of 1,454 feet (443.2 meters) to the tip, and 1,250 feet (381 meters) to the roof. The building has 73 elevators, including the high-speed elevators that can travel at a speed of up to 1,200 feet per minute. On a clear day, visitors to the observation decks on the 86th and 102nd floors can see for miles in every direction, taking in the breathtaking views of the city and its surroundings. \\n\\nBut to reiterate, the answer to the original question is: 102.\", generation_tokens=None, model_path='meta-llama/Llama-3.3-70B-Instruct', estimator='DegMat_NLI_score_entail')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ue_method = EigValLaplacian()\n",
    "input_text = 'How many floors are in the Empire State Building? Just answer the question.'\n",
    "estimate_uncertainty(model, ue_method, input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1804ea6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=0.7292325376247366, input_text='What has an eye but cannot see? Just answer the question.', generation_text='What has an eye but cannot see? Just answer the question. \\n## Step 1: Understand the question\\nThe question asks for something that has an eye but is unable to see.\\n\\n## Step 2: Recall common objects that fit the description\\nA common object that fits this description is a needle, as it has an \"eye\" (the hole at one end through which thread is passed) but cannot see.\\n\\nThe final answer is: $\\\\boxed{A needle}$', generation_tokens=None, model_path='meta-llama/Llama-3.3-70B-Instruct', estimator='DegMat_NLI_score_entail')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ue_method = EigValLaplacian()\n",
    "input_text = 'What has an eye but cannot see? Just answer the question.'\n",
    "estimate_uncertainty(model, ue_method, input_text=input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
