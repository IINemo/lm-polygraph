{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d24995",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f565f3-5542-451f-ba22-db777274166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.5)\n",
      "Requirement already satisfied: jinja2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (78.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.4.26)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Assume that you have installed lm-polygraph: \n",
    "# pip install git+https://github.com/artemshelmanov/lm-polygraph.git\n",
    "\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b6bc2",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a39633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6958a441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-23 18:05:42 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 18:05:44,345\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Gemma3ForCausalLM\n",
    "from lm_polygraph.utils.model import WhiteboxModel, BlackboxModel\n",
    "from lm_polygraph import estimate_uncertainty\n",
    "from lm_polygraph.estimators import MaximumTokenProbability, MaximumSequenceProbability, SemanticEntropy, EigValLaplacian\n",
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8642d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4afc22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA RTX 5000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e48fa8",
   "metadata": {},
   "source": [
    "### Try vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2acfecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vllm\n",
      "  Downloading vllm-0.9.1-cp38-abi3-manylinux1_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: regex in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (2024.11.6)\n",
      "Requirement already satisfied: cachetools in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (6.1.0)\n",
      "Requirement already satisfied: psutil in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (7.0.0)\n",
      "Requirement already satisfied: sentencepiece in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (0.1.99)\n",
      "Requirement already satisfied: numpy in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (4.67.1)\n",
      "Collecting blake3 (from vllm)\n",
      "  Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting py-cpuinfo (from vllm)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: transformers>=4.51.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (4.52.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.32.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from huggingface-hub[hf_xet]>=0.32.0->vllm) (0.32.6)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: protobuf in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (4.25.8)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
      "Requirement already satisfied: aiohttp in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (3.12.12)\n",
      "Requirement already satisfied: openai>=1.52.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (1.86.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (2.11.5)\n",
      "Collecting prometheus_client>=0.18.0 (from vllm)\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (11.2.1)\n",
      "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
      "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (0.9.0)\n",
      "Collecting lm-format-enforcer<0.11,>=0.10.11 (from vllm)\n",
      "  Downloading lm_format_enforcer-0.10.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
      "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting outlines==0.1.11 (from vllm)\n",
      "  Downloading outlines-0.1.11-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lark==1.2.2 (from vllm)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xgrammar==0.1.19 (from vllm)\n",
      "  Downloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (4.14.0)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (3.18.0)\n",
      "Collecting partial-json-parser (from vllm)\n",
      "  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (26.2.0)\n",
      "Collecting msgspec (from vllm)\n",
      "  Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting gguf>=0.13.0 (from vllm)\n",
      "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting mistral_common>=1.5.4 (from mistral_common[opencv]>=1.5.4->vllm)\n",
      "  Downloading mistral_common-1.6.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting opencv-python-headless>=4.11.0 (from vllm)\n",
      "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pyyaml in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (6.0.2)\n",
      "Requirement already satisfied: einops in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (0.8.1)\n",
      "Collecting compressed-tensors==0.10.1 (from vllm)\n",
      "  Downloading compressed_tensors-0.10.1-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting depyf==0.18.0 (from vllm)\n",
      "  Downloading depyf-0.18.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting cloudpickle (from vllm)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting watchfiles (from vllm)\n",
      "  Downloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting python-json-logger (from vllm)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: scipy in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from vllm) (1.15.3)\n",
      "Collecting ninja (from vllm)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-api>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp>=1.26.0 (from vllm)\n",
      "  Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-semantic-conventions-ai>=0.4.1 (from vllm)\n",
      "  Downloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting numba==0.61.2 (from vllm)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting ray!=2.44.*,>=2.43.0 (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "  Downloading ray-2.47.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting torch==2.7.0 (from vllm)\n",
      "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchaudio==2.7.0 (from vllm)\n",
      "  Downloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchvision==0.22.0 (from vllm)\n",
      "  Downloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting xformers==0.0.30 (from vllm)\n",
      "  Downloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting astor (from depyf==0.18.0->vllm)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: dill in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting interegular (from outlines==0.1.11->vllm)\n",
      "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: jinja2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (4.24.0)\n",
      "Collecting pycountry (from outlines==0.1.11->vllm)\n",
      "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting airportsdata (from outlines==0.1.11->vllm)\n",
      "  Downloading airportsdata-20250622-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting outlines_core==0.1.26 (from outlines==0.1.11->vllm)\n",
      "  Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from torch==2.7.0->vllm) (1.11.1.6)\n",
      "Collecting triton==3.3.0 (from torch==2.7.0->vllm)\n",
      "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from triton==3.3.0->torch==2.7.0->vllm) (78.1.1)\n",
      "Requirement already satisfied: packaging in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from lm-format-enforcer<0.11,>=0.10.11->vllm) (25.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic>=2.10->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic>=2.10->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from pydantic>=2.10->vllm) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.1)\n",
      "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Collecting python-multipart>=0.0.18 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.3)\n",
      "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: typer>=0.12.3 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading rich_toolkit-0.14.7-py3-none-any.whl.metadata (999 bytes)\n",
      "Requirement already satisfied: certifi in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from huggingface-hub>=0.32.0->huggingface-hub[hf_xet]>=0.32.0->vllm) (1.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "Collecting sentencepiece (from vllm)\n",
      "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.25.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (0.10.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.26.0->vllm)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.26.0->vllm)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.34.1 (from opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.34.1 (from opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting grpcio<2.0.0,>=1.63.2 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading grpcio-1.73.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc==1.34.1->opentelemetry-exporter-otlp>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from vllm)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.26.0->vllm)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.2.1)\n",
      "Collecting msgpack<2.0.0,>=1.0.0 (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Collecting cupy-cuda12x (from ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "  Downloading cupy_cuda12x-13.4.1-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: rich>=13.7.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (14.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/arina.kostina/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages (from aiohttp->vllm) (1.20.1)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm)\n",
      "  Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading vllm-0.9.1-cp38-abi3-manylinux1_x86_64.whl (394.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.6/394.6 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading compressed_tensors-0.10.1-py3-none-any.whl (116 kB)\n",
      "Downloading depyf-0.18.0-py3-none-any.whl (38 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m155.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading outlines-0.1.11-py3-none-any.whl (87 kB)\n",
      "Downloading outlines_core-0.1.26-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchaudio-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m148.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.30-cp310-cp310-manylinux_2_28_x86_64.whl (31.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgrammar-0.1.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m170.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lm_format_enforcer-0.10.11-py3-none-any.whl (44 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
      "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
      "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
      "Downloading mistral_common-1.6.2-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.34.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.34.1-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading grpcio-1.73.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m190.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading opentelemetry_semantic_conventions_ai-0.4.9-py3-none-any.whl (5.6 kB)\n",
      "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ray-2.47.1-cp310-cp310-manylinux2014_x86_64.whl (68.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "Downloading rich_toolkit-0.14.7-py3-none-any.whl (24 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m169.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading airportsdata-20250622-py3-none-any.whl (912 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.7/912.7 kB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading blake3-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cupy_cuda12x-13.4.1-cp310-cp310-manylinux2014_x86_64.whl (104.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "Downloading msgspec-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n",
      "Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: sentencepiece, py-cpuinfo, fastrlock, blake3, zipp, websockets, uvloop, triton, python-multipart, python-json-logger, pycountry, protobuf, prometheus_client, partial-json-parser, opentelemetry-semantic-conventions-ai, opencv-python-headless, ninja, msgspec, msgpack, llvmlite, llguidance, lark, interegular, httptools, grpcio, gguf, dnspython, cupy-cuda12x, cloudpickle, astor, airportsdata, opentelemetry-proto, numba, importlib-metadata, googleapis-common-protos, email-validator, depyf, watchfiles, torch, rich-toolkit, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, lm-format-enforcer, xformers, torchvision, torchaudio, ray, prometheus-fastapi-instrumentator, outlines_core, opentelemetry-semantic-conventions, mistral_common, xgrammar, outlines, opentelemetry-sdk, fastapi-cli, compressed-tensors, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp, vllm\n",
      "\u001b[2K  Attempting uninstall: sentencepiece\n",
      "\u001b[2K    Found existing installation: sentencepiece 0.1.99\n",
      "\u001b[2K    Uninstalling sentencepiece-0.1.99:\n",
      "\u001b[2K      Successfully uninstalled sentencepiece-0.1.99\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/60\u001b[0m [websockets]\n",
      "\u001b[2K    Found existing installation: triton 3.3.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/60\u001b[0m [websockets]\n",
      "\u001b[2K    Uninstalling triton-3.3.1:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/60\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/60\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: protobufm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/60\u001b[0m [pycountry]tipart]\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.8━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/60\u001b[0m [pycountry]\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/60\u001b[0m [pycountry]\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.8━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/60\u001b[0m [pycountry]\n",
      "\u001b[2K  Attempting uninstall: torch━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/60\u001b[0m [depyf]apis-common-protos]-ai]\n",
      "\u001b[2K    Found existing installation: torch 2.7.190m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/60\u001b[0m [depyf]\n",
      "\u001b[2K    Uninstalling torch-2.7.1:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/60\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/60\u001b[0m [torch]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60/60\u001b[0m [vllm]0m [vllm]lemetry-exporter-otlp-proto-http]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unbabel-comet 2.2.1 requires protobuf<5.0.0,>=4.24.4, but you have protobuf 5.29.5 which is incompatible.\n",
      "unbabel-comet 2.2.1 requires sentencepiece<0.2.0,>=0.1.96, but you have sentencepiece 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed airportsdata-20250622 astor-0.8.1 blake3-1.0.5 cloudpickle-3.1.1 compressed-tensors-0.10.1 cupy-cuda12x-13.4.1 depyf-0.18.0 dnspython-2.7.0 email-validator-2.2.0 fastapi-cli-0.0.7 fastrlock-0.8.3 gguf-0.17.1 googleapis-common-protos-1.70.0 grpcio-1.73.0 httptools-0.6.4 importlib-metadata-8.7.0 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.10.11 mistral_common-1.6.2 msgpack-1.1.1 msgspec-0.19.0 ninja-1.11.1.4 numba-0.61.2 opencv-python-headless-4.11.0.86 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-exporter-otlp-proto-http-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-semantic-conventions-ai-0.4.9 outlines-0.1.11 outlines_core-0.1.26 partial-json-parser-0.2.1.1.post5 prometheus-fastapi-instrumentator-7.1.0 prometheus_client-0.22.1 protobuf-5.29.5 py-cpuinfo-9.0.0 pycountry-24.6.1 python-json-logger-3.3.0 python-multipart-0.0.20 ray-2.47.1 rich-toolkit-0.14.7 sentencepiece-0.2.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0 triton-3.3.0 uvloop-0.21.0 vllm-0.9.1 watchfiles-1.1.0 websockets-15.0.1 xformers-0.0.30 xgrammar-0.1.19 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "371574d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0dba63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-23 18:06:05 [config.py:823] This model supports multiple tasks: {'classify', 'reward', 'embed', 'generate', 'score'}. Defaulting to 'generate'.\n",
      "INFO 06-23 18:06:05 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 06-23 18:06:05 [config.py:2232] max_num_batched_tokens (8192) exceeds max_num_seqs* max_model_len (5120). This may lead to unexpected behavior.\n",
      "WARNING 06-23 18:06:07 [utils.py:2597] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "WARNING 06-23 18:06:08 [env_override.py:17] NCCL_CUMEM_ENABLE is set to 0, skipping override. This may increase memory overhead with cudagraph+allreduce: https://github.com/NVIDIA/nccl/issues/1234\n",
      "INFO 06-23 18:06:11 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 06-23 18:06:14 [core.py:455] Waiting for init message from front-end.\n",
      "INFO 06-23 18:06:14 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=20, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "WARNING 06-23 18:06:14 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x1536e70cc850>\n",
      "INFO 06-23 18:06:15 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-23 18:06:15 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-23 18:06:15 [gpu_model_runner.py:1595] Starting to load model meta-llama/Llama-3.1-8B-Instruct...\n",
      "INFO 06-23 18:06:15 [gpu_model_runner.py:1600] Loading model from scratch...\n",
      "INFO 06-23 18:06:15 [cuda.py:252] Using Flash Attention backend on V1 engine.\n",
      "INFO 06-23 18:06:16 [weight_utils.py:292] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  7.35it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.35it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.74it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.77it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-23 18:06:19 [default_loader.py:272] Loading weights took 2.45 seconds\n",
      "INFO 06-23 18:06:19 [gpu_model_runner.py:1624] Model loading took 14.9889 GiB and 4.119997 seconds\n",
      "INFO 06-23 18:06:26 [backends.py:462] Using cache directory: /home/arina.kostina/.cache/vllm/torch_compile_cache/5e9ec81a24/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-23 18:06:26 [backends.py:472] Dynamo bytecode transform time: 6.15 s\n",
      "INFO 06-23 18:06:30 [backends.py:135] Directly load the compiled graph(s) for shape None from the cache, took 3.929 s\n",
      "INFO 06-23 18:06:30 [monitor.py:34] torch.compile takes 6.15 s in total\n",
      "INFO 06-23 18:06:32 [gpu_worker.py:227] Available KV cache memory: 12.19 GiB\n",
      "INFO 06-23 18:06:32 [kv_cache_utils.py:715] GPU KV cache size: 99,888 tokens\n",
      "INFO 06-23 18:06:32 [kv_cache_utils.py:719] Maximum concurrency for 20 tokens per request: 3121.50x\n",
      "INFO 06-23 18:06:51 [gpu_model_runner.py:2048] Graph capturing finished in 19 secs, took 0.52 GiB\n",
      "INFO 06-23 18:06:51 [core.py:171] init engine (profile, create kv cache, warmup model) took 31.83 seconds\n"
     ]
    }
   ],
   "source": [
    "model = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# 'google/gemma-3-12b-it'\n",
    "\n",
    "llm = LLM(model=model, max_model_len=20)\n",
    "# llm = LLM(model=model, max_model_len=4096, gpu_memory_utilization=0.9, quantization=\"awq\", dtype=\"half\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model,\n",
    "    trust_remote_code = True\n",
    ")\n",
    "\n",
    "sampling_params = SamplingParams(temperature=0, top_p=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f360d87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding requests: 100%|██████████| 3/3 [00:00<00:00, 1885.08it/s]\n",
      "Processed prompts: 100%|██████████| 3/3 [00:00<00:00,  6.57it/s, est. speed input: 43.80 toks/s, output: 87.59 toks/s]\n"
     ]
    }
   ],
   "source": [
    "prompt = ['What is Artifficial intelligence?', 'What is parallel programming?', 'What is kek?']\n",
    "\n",
    "outputs = llm.generate(prompt, sampling_params)\n",
    "answers = []\n",
    "for p in outputs:\n",
    "  out = p.outputs[0].text\n",
    "  answers.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "badf6365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Artificial intelligence (AI) is a broad field of computer science', ' Parallel programming is a technique used to improve the performance of a program by', ' Kek is a popular internet meme that has been around since 201']\n"
     ]
    }
   ],
   "source": [
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49816b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = WhiteboxModel(llm, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a10c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lm_polygraph.utils.model.WhiteboxModel at 0x1491d8956920>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "865d4c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m estimator \u001b[38;5;241m=\u001b[39m MaximumSequenceProbability()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# results = []\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is AI?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/estimate_uncertainty.py:99\u001b[0m, in \u001b[0;36mestimate_uncertainty\u001b[0;34m(model, estimator, input_text)\u001b[0m\n\u001b[1;32m     84\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlackbox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m man \u001b[38;5;241m=\u001b[39m UEManager(\n\u001b[1;32m     86\u001b[0m     Dataset([input_text], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     87\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n\u001b[0;32m---> 99\u001b[0m \u001b[43mman\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m ue \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mestimations[estimator\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;28mstr\u001b[39m(estimator)]\n\u001b[1;32m    101\u001b[0m texts \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreedy_texts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:404\u001b[0m, in \u001b[0;36mUEManager.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors:\n\u001b[1;32m    402\u001b[0m         processor\u001b[38;5;241m.\u001b[39mon_batch(batch_stats, batch_gen_metrics, batch_estimations)\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_on_batch_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (gen_level, gen_name), generation_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ue_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mue_metrics:\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:337\u001b[0m, in \u001b[0;36mUEManager._process\u001b[0;34m(self, iterable_data, batch_callback)\u001b[0m\n\u001b[1;32m    334\u001b[0m     batch_stats[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    335\u001b[0m batch_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m--> 337\u001b[0m batch_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_calculators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m batch_estimations, bad_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate(\n\u001b[1;32m    340\u001b[0m     batch_stats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators\n\u001b[1;32m    341\u001b[0m )\n\u001b[1;32m    343\u001b[0m batch_callback(\n\u001b[1;32m    344\u001b[0m     batch_i, target_texts, batch_stats, batch_estimations, bad_estimators\n\u001b[1;32m    345\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:278\u001b[0m, in \u001b[0;36mUEManager.calculate\u001b[0;34m(self, batch_stats, calculators, inp_texts)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_stats\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:254\u001b[0m, in \u001b[0;36mUEManager.calculate\u001b[0;34m(self, batch_stats, calculators, inp_texts)\u001b[0m\n\u001b[1;32m    252\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    253\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m new_stats \u001b[38;5;241m=\u001b[39m \u001b[43mstat_calculator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_time:\n\u001b[1;32m    258\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone calculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/stat_calculators/greedy_probs.py:76\u001b[0m, in \u001b[0;36mGreedyProbsCalculator.__call__\u001b[0;34m(self, dependencies, texts, model, max_new_tokens)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mCalculates the statistics of probabilities at each token position in the generation.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        - 'greedy_log_likelihoods' (List[List[float]]): log-probabilities of the generated tokens.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m batch: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenize(texts)\n\u001b[0;32m---> 76\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     78\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch,\n\u001b[1;32m     80\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m         ),\n\u001b[1;32m     96\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/stat_calculators/greedy_probs.py:76\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mCalculates the statistics of probabilities at each token position in the generation.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m        - 'greedy_log_likelihoods' (List[List[float]]): log-probabilities of the generated tokens.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m batch: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenize(texts)\n\u001b[0;32m---> 76\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     78\u001b[0m     out \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch,\n\u001b[1;32m     80\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m         ),\n\u001b[1;32m     96\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/model.py:591\u001b[0m, in \u001b[0;36mWhiteboxModel.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdevice\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    585\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m    Returns the device the model is currently loaded on.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m        str: device string.\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LLM' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "estimator = MaximumSequenceProbability()\n",
    "# results = []\n",
    "ans = estimate_uncertainty(model, estimator, input_text=\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    # device_map='cpu',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459f454",
   "metadata": {},
   "source": [
    "## UQ for Whitebox LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dc0e6-804f-490e-9b77-4f5b3cb0ad64",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f31379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the token from the environment\n",
    "mytoken = os.getenv(\"HF_TOKEN\")\n",
    "mytoken2 = os.getenv(\"HF_TOKEN2\")\n",
    "\n",
    "# Example: Use the token with Hugging Face Hub API\n",
    "# api = HfApi(token=mytoken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234fd08",
   "metadata": {},
   "source": [
    "### Final Formating !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8afff62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: 18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'main/train-00000-of-00001.parquet', 'test': 'main/test-00000-of-00001.parquet'}\n",
    "\n",
    "base_path = \"hf://datasets/openai/gsm8k/\"\n",
    "\n",
    "# Read both train and test splits, adding a column to indicate the split\n",
    "train_df = pd.read_parquet(base_path + splits[\"train\"])\n",
    "train_df[\"split\"] = \"train\"\n",
    "test_df = pd.read_parquet(base_path + splits[\"test\"])\n",
    "test_df[\"split\"] = \"test\"\n",
    "\n",
    "train_df['answer'] = train_df['answer'].str.split('####').str[1].str.strip()\n",
    "test_df['answer'] = test_df['answer'].str.split('####').str[1].str.strip()\n",
    "\n",
    "# Preview the result\n",
    "print('answer:', test_df['answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "short = \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\"\n",
    "\n",
    "train_df['question'] = train_df['question'].apply(lambda q: short.replace(\"{question}\", q))\n",
    "test_df['question'] = test_df['question'].apply(lambda q: short.replace(\"{question}\", q))\n",
    "\n",
    "test_df = test_df.drop('split', axis=1)\n",
    "train_df = train_df.drop('split', axis=1)\n",
    "\n",
    "train_df.to_csv(f'gsm8k-direct/train.csv', index=False)\n",
    "test_df.to_csv(f'gsm8k-direct/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa44f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot = \"Answer the following question, by explaining your reasoning step-by-step in a single paragraph to determine the correct answer for the following question. After your reasoning, state the single correct numerical value (int), no other symbols, only one integer for the answer on a new line, prefixed with '### Answer:'.\\n{question}\"\n",
    "\n",
    "train_df['question'] = train_df['question'].apply(lambda q: cot.replace(\"{question}\", q))\n",
    "test_df['question'] = test_df['question'].apply(lambda q: cot.replace(\"{question}\", q))\n",
    "\n",
    "test_df = test_df.drop('split', axis=1)\n",
    "train_df = train_df.drop('split', axis=1)\n",
    "\n",
    "train_df.to_csv(f'gsm8k-reasoning/train.csv', index=False)\n",
    "test_df.to_csv(f'gsm8k-reasoning/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91dc1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf480f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/UGRIP-LM-Polygraph/gsm8k-direct/commit/b464547c2f26ff12a64618f16bb641b5f30319dc', commit_message='Upload gsm8k-direct/test.csv with huggingface_hub', commit_description='', oid='b464547c2f26ff12a64618f16bb641b5f30319dc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/UGRIP-LM-Polygraph/gsm8k-direct', endpoint='https://huggingface.co', repo_type='dataset', repo_id='UGRIP-LM-Polygraph/gsm8k-direct'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HfApi(token=mytoken2)\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"gsm8k-direct/test.csv\",\n",
    "    path_in_repo=\"gsm8k-direct/test.csv\",\n",
    "    repo_id=\"UGRIP-LM-Polygraph/gsm8k-direct\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"gsm8k-direct/train.csv\",\n",
    "    path_in_repo=\"gsm8k-direct/train.csv\",\n",
    "    repo_id=\"UGRIP-LM-Polygraph/gsm8k-direct\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"gsm8k-reasoning/test.csv\",\n",
    "    path_in_repo=\"gsm8k-reasoning/test.csv\",\n",
    "    repo_id=\"UGRIP-LM-Polygraph/gsm8k-reasoning\",\n",
    "    repo_type=\"dataset\"\n",
    ")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"gsm8k-reasoning/train.csv\",\n",
    "    path_in_repo=\"gsm8k-reasoning/train.csv\",\n",
    "    repo_id=\"UGRIP-LM-Polygraph/gsm8k-reasoning\",\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96afdfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(train_df['question'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b6eae3",
   "metadata": {},
   "source": [
    "### openai/gsm8k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2923c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'main/train-00000-of-00001.parquet', 'test': 'main/test-00000-of-00001.parquet'}\n",
    "\n",
    "base_path = \"hf://datasets/openai/gsm8k/\"\n",
    "\n",
    "# Read both train and test splits, adding a column to indicate the split\n",
    "train_df = pd.read_parquet(base_path + splits[\"train\"])\n",
    "train_df[\"split\"] = \"train\"\n",
    "test_df = pd.read_parquet(base_path + splits[\"test\"])\n",
    "test_df[\"split\"] = \"test\"\n",
    "\n",
    "# Combine into one DataFrame\n",
    "gsm8k_df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d659c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia sold clips to 48 of her friends in Apr...</td>\n",
       "      <td>Natalia sold 48/2 = &lt;&lt;48/2=24&gt;&gt;24 clips in May...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weng earns $12 an hour for babysitting. Yester...</td>\n",
       "      <td>Weng earns 12/60 = $&lt;&lt;12/60=0.2&gt;&gt;0.2 per minut...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betty is saving money for a new wallet which c...</td>\n",
       "      <td>In the beginning, Betty has only 100 / 2 = $&lt;&lt;...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Julie is reading a 120-page book. Yesterday, s...</td>\n",
       "      <td>Maila read 12 x 2 = &lt;&lt;12*2=24&gt;&gt;24 pages today....</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James writes a 3-page letter to 2 different fr...</td>\n",
       "      <td>He writes each friend 3*2=&lt;&lt;3*2=6&gt;&gt;6 pages a w...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8787</th>\n",
       "      <td>John had a son James when he was 19.  James is...</td>\n",
       "      <td>Dora is 12-3=&lt;&lt;12-3=9&gt;&gt;9\\nSo James is 9*2=&lt;&lt;9*...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td>There are some oranges in a basket. Ana spends...</td>\n",
       "      <td>There are 60 minutes in an hour. Ana peels an ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8789</th>\n",
       "      <td>Mark's car breaks down and he needs to get a n...</td>\n",
       "      <td>The discount on the radiator was 400*.8=$&lt;&lt;400...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8790</th>\n",
       "      <td>Farmer Brown has 20 animals on his farm, all e...</td>\n",
       "      <td>Let C be the number of chickens.\\nThere are 20...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8791</th>\n",
       "      <td>Henry and 3 of his friends order 7 pizzas for ...</td>\n",
       "      <td>There are 7*8=&lt;&lt;7*8=56&gt;&gt;56 slices in total.\\nT...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8792 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0     Natalia sold clips to 48 of her friends in Apr...   \n",
       "1     Weng earns $12 an hour for babysitting. Yester...   \n",
       "2     Betty is saving money for a new wallet which c...   \n",
       "3     Julie is reading a 120-page book. Yesterday, s...   \n",
       "4     James writes a 3-page letter to 2 different fr...   \n",
       "...                                                 ...   \n",
       "8787  John had a son James when he was 19.  James is...   \n",
       "8788  There are some oranges in a basket. Ana spends...   \n",
       "8789  Mark's car breaks down and he needs to get a n...   \n",
       "8790  Farmer Brown has 20 animals on his farm, all e...   \n",
       "8791  Henry and 3 of his friends order 7 pizzas for ...   \n",
       "\n",
       "                                                 answer  split  \n",
       "0     Natalia sold 48/2 = <<48/2=24>>24 clips in May...  train  \n",
       "1     Weng earns 12/60 = $<<12/60=0.2>>0.2 per minut...  train  \n",
       "2     In the beginning, Betty has only 100 / 2 = $<<...  train  \n",
       "3     Maila read 12 x 2 = <<12*2=24>>24 pages today....  train  \n",
       "4     He writes each friend 3*2=<<3*2=6>>6 pages a w...  train  \n",
       "...                                                 ...    ...  \n",
       "8787  Dora is 12-3=<<12-3=9>>9\\nSo James is 9*2=<<9*...   test  \n",
       "8788  There are 60 minutes in an hour. Ana peels an ...   test  \n",
       "8789  The discount on the radiator was 400*.8=$<<400...   test  \n",
       "8790  Let C be the number of chickens.\\nThere are 20...   test  \n",
       "8791  There are 7*8=<<7*8=56>>56 slices in total.\\nT...   test  \n",
       "\n",
       "[8792 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm8k_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0220b65",
   "metadata": {},
   "source": [
    "#### Create column 'short_answer' with answers without reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2433ef93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\n",
      "#### 72\n",
      "short_answer: 72\n"
     ]
    }
   ],
   "source": [
    "gsm8k_df['short_answer'] = gsm8k_df['answer'].str.split('####').str[1].str.strip()\n",
    "\n",
    "# Preview the result\n",
    "print('answer:', gsm8k_df['answer'].iloc[0])\n",
    "print('short_answer:', gsm8k_df['short_answer'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec242a",
   "metadata": {},
   "source": [
    "#### Create column 'cot_question' for reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7a7afe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Gemma3ForCausalLM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoogle/gemma-3-12b-it\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 'google/gemma-3-12b-it'\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 'deepseek-ai/deepseek-llm-7b-chat'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 'meta-llama/Llama-3.1-8B-Instruct'\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 'microsoft/phi-4'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 'Qwen/Qwen2.5-7B-Instruct'\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mGemma3ForCausalLM\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained( \u001b[38;5;66;03m# AutoModelForCausalLM.from_pretrained(\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     model_name,\n\u001b[1;32m     10\u001b[0m     token\u001b[38;5;241m=\u001b[39mmytoken,\n\u001b[1;32m     11\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m# 'cpu',\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     14\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token  \u001b[38;5;66;03m# Use EOS as PAD for the mistral 7B\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Gemma3ForCausalLM' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# 'google/gemma-3-12b-it'\n",
    "# 'deepseek-ai/deepseek-llm-7b-chat'\n",
    "# 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# 'microsoft/phi-4'\n",
    "# 'Qwen/Qwen2.5-7B-Instruct'\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained( # Gemma3ForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    token=mytoken,\n",
    "    device_map='auto' # 'cpu',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use EOS as PAD for the mistral 7B\n",
    "\n",
    "model = WhiteboxModel(base_model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3972e0",
   "metadata": {},
   "source": [
    "#### Create column 'short_question' without reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34305786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 0, Question 0\n",
      "Answer this question strictly with the final numerical value. No words, steps, or additional text allowed.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "96<end_of_turn>\n",
      "\n",
      "Prompt 0, Question 1\n",
      "Answer this question strictly with the final numerical value. No words, steps, or additional text allowed.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "10\n",
      "<end_of_turn>\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m prompts[i]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Estimate uncertainty\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Collect result\u001b[39;00m\n\u001b[1;32m     22\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: i,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: j,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m: ans\n\u001b[1;32m     29\u001b[0m })\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/estimate_uncertainty.py:99\u001b[0m, in \u001b[0;36mestimate_uncertainty\u001b[0;34m(model, estimator, input_text)\u001b[0m\n\u001b[1;32m     84\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlackbox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m man \u001b[38;5;241m=\u001b[39m UEManager(\n\u001b[1;32m     86\u001b[0m     Dataset([input_text], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     87\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n\u001b[0;32m---> 99\u001b[0m \u001b[43mman\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m ue \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mestimations[estimator\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;28mstr\u001b[39m(estimator)]\n\u001b[1;32m    101\u001b[0m texts \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreedy_texts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:404\u001b[0m, in \u001b[0;36mUEManager.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors:\n\u001b[1;32m    402\u001b[0m         processor\u001b[38;5;241m.\u001b[39mon_batch(batch_stats, batch_gen_metrics, batch_estimations)\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_on_batch_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (gen_level, gen_name), generation_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ue_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mue_metrics:\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:337\u001b[0m, in \u001b[0;36mUEManager._process\u001b[0;34m(self, iterable_data, batch_callback)\u001b[0m\n\u001b[1;32m    334\u001b[0m     batch_stats[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    335\u001b[0m batch_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m--> 337\u001b[0m batch_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_calculators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m batch_estimations, bad_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate(\n\u001b[1;32m    340\u001b[0m     batch_stats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators\n\u001b[1;32m    341\u001b[0m )\n\u001b[1;32m    343\u001b[0m batch_callback(\n\u001b[1;32m    344\u001b[0m     batch_i, target_texts, batch_stats, batch_estimations, bad_estimators\n\u001b[1;32m    345\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:254\u001b[0m, in \u001b[0;36mUEManager.calculate\u001b[0;34m(self, batch_stats, calculators, inp_texts)\u001b[0m\n\u001b[1;32m    252\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    253\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m new_stats \u001b[38;5;241m=\u001b[39m \u001b[43mstat_calculator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_time:\n\u001b[1;32m    258\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone calculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/stat_calculators/greedy_probs.py:78\u001b[0m, in \u001b[0;36mGreedyProbsCalculator.__call__\u001b[0;34m(self, dependencies, texts, model, max_new_tokens)\u001b[0m\n\u001b[1;32m     76\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 78\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_newlines\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                \u001b[49m\u001b[43mt\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out\u001b[38;5;241m.\u001b[39mscores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvLLMCausalLM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/model.py:535\u001b[0m, in \u001b[0;36mWhiteboxModel.generate\u001b[0;34m(self, **args)\u001b[0m\n\u001b[1;32m    532\u001b[0m args \u001b[38;5;241m=\u001b[39m default_params\n\u001b[1;32m    533\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args(args)\n\u001b[0;32m--> 535\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# override generation.scores with original scores from model\u001b[39;00m\n\u001b[1;32m    538\u001b[0m generation\u001b[38;5;241m.\u001b[39mgeneration_scores \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mscores\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2594\u001b[0m     )\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/generation/utils.py:3560\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3560\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3564\u001b[0m     outputs,\n\u001b[1;32m   3565\u001b[0m     model_kwargs,\n\u001b[1;32m   3566\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3567\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:864\u001b[0m, in \u001b[0;36mGemma3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    861\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    862\u001b[0m )\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:654\u001b[0m, in \u001b[0;36mGemma3TextModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    642\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    643\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         cache_position,\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:479\u001b[0m, in \u001b[0;36mGemma3DecoderLayer.forward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    478\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_feedforward_layernorm(hidden_states)\n\u001b[0;32m--> 479\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_feedforward_layernorm(hidden_states)\n\u001b[1;32m    481\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/hooks.py:175\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:159\u001b[0m, in \u001b[0;36mGemma3MLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 159\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/hooks.py:170\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnew_forward\u001b[39m(module, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 170\u001b[0m     args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hf_hook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mno_grad:\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/hooks.py:360\u001b[0m, in \u001b[0;36mAlignDevicesHook.pre_forward\u001b[0;34m(self, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    353\u001b[0m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    354\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    355\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdata_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map\n\u001b[1;32m    356\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_params_map[value\u001b[38;5;241m.\u001b[39mdata_ptr()]\n\u001b[1;32m    357\u001b[0m         ):\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtied_pointers_to_remove\u001b[38;5;241m.\u001b[39madd((value\u001b[38;5;241m.\u001b[39mdata_ptr(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device))\n\u001b[0;32m--> 360\u001b[0m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device), send_to_device(\n\u001b[1;32m    370\u001b[0m     kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_device, skip_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_keys\n\u001b[1;32m    371\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/accelerate/utils/modeling.py:337\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[0;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[1;32m    335\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 337\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Answer this question strictly with the final numerical value. No words, steps, or additional text allowed.\\n{question}\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\",\n",
    "    \"Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\n{question}\\nStricktly follow the below answer format:\\nvalue\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\",\n",
    "]\n",
    "\n",
    "estimator = MaximumSequenceProbability()\n",
    "results = []\n",
    "\n",
    "for i in range(0, len(prompts)):\n",
    "    # Replace {question} in the prompt for each of the first 5 questions\n",
    "    for j in range(20):\n",
    "        question = gsm8k_df['question'].iloc[j]\n",
    "        prompt_text = prompts[i].replace(\"{question}\", question)\n",
    "\n",
    "        # Estimate uncertainty\n",
    "        ans = estimate_uncertainty(model, estimator, input_text=prompt_text)\n",
    "\n",
    "        # Collect result\n",
    "        results.append({\n",
    "            \"prompt_index\": i,\n",
    "            \"question_index\": j,\n",
    "            \"input_text\": ans.input_text,\n",
    "            \"generation_text\": ans.generation_text,\n",
    "            \"ground_truth\": gsm8k_df['short_answer'].iloc[j],\n",
    "            \"all\": ans\n",
    "        })\n",
    "\n",
    "        # Optionally print\n",
    "        print(f\"Prompt {i}, Question {j}\")\n",
    "        print(ans.input_text)\n",
    "        print(ans.generation_text)\n",
    "        print()\n",
    "\n",
    "\n",
    "# Convert new results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "try:\n",
    "    # Load existing results\n",
    "    dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}.csv')\n",
    "    # Append new results\n",
    "    combined_df = pd.concat([dftemp, results_df], ignore_index=True)\n",
    "    # Save the combined DataFrame back to CSV\n",
    "    combined_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}.csv', index=False)\n",
    "except:\n",
    "    results_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c520824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 2, Question 0\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "120\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nStricktly follow the below answer format:\\nvalue\\n```\\n120\\n```'}]\n",
      "\n",
      "Prompt 2, Question 1\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "10\n",
      "```\n",
      "10\n",
      "```\n",
      "10\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nWeng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\\nStricktly follow the below answer format:\\nvalue\\n```\\n10\\n```\\n10\\n```\\n10\\n```'}]\n",
      "\n",
      "Prompt 2, Question 2\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "100\n",
      "\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nBetty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\\nStricktly follow the below answer format:\\nvalue\\n100\\n'}]\n",
      "\n",
      "Prompt 2, Question 3\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "30\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nJulie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\\nStricktly follow the below answer format:\\nvalue\\n```\\n30\\n```'}]\n",
      "\n",
      "Prompt 2, Question 4\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "1056\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nJames writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\\nStricktly follow the below answer format:\\nvalue\\n```\\n1056\\n```'}]\n",
      "\n",
      "Prompt 2, Question 5\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "189\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nMark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\\nStricktly follow the below answer format:\\nvalue\\n```\\n189\\n```'}]\n",
      "\n",
      "Prompt 2, Question 6\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "56\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nAlbert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\\nStricktly follow the below answer format:\\nvalue\\n```\\n56\\n```'}]\n",
      "\n",
      "Prompt 2, Question 7\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "10\n",
      "```\n",
      "16\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nKen created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\\nStricktly follow the below answer format:\\nvalue\\n10\\n```\\n16\\n```'}]\n",
      "\n",
      "Prompt 2, Question 8\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "67\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nAlexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\\nStricktly follow the below answer format:\\nvalue\\n```\\n67\\n```'}]\n",
      "\n",
      "Prompt 2, Question 9\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "1170\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nTina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\\nStricktly follow the below answer format:\\nvalue\\n```\\n1170\\n```'}]\n",
      "\n",
      "Prompt 2, Question 10\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "148\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nA deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\\nStricktly follow the below answer format:\\nvalue\\n```\\n148\\n```'}]\n",
      "\n",
      "Prompt 2, Question 11\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "11\n",
      "\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nTobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\\nStricktly follow the below answer format:\\nvalue\\n11\\n'}]\n",
      "\n",
      "Prompt 2, Question 12\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "115\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nRandy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\\nStricktly follow the below answer format:\\nvalue\\n```\\n115\\n```'}]\n",
      "\n",
      "Prompt 2, Question 13\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "32\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nJasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\\nStricktly follow the below answer format:\\nvalue\\n```\\n32\\n```'}]\n",
      "\n",
      "Prompt 2, Question 14\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "2.5\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nJoy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\nStricktly follow the below answer format:\\nvalue\\n```\\n2.5\\n```'}]\n",
      "\n",
      "Prompt 2, Question 15\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "115000\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nJames creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\\nStricktly follow the below answer format:\\nvalue\\n```\\n115000\\n```'}]\n",
      "\n",
      "Prompt 2, Question 16\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "4800\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nThe profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\\nStricktly follow the below answer format:\\nvalue\\n```\\n4800\\n```'}]\n",
      "\n",
      "Prompt 2, Question 17\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "26+15+24-4-6-12 = 43\n",
      "43\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nIn a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\\nStricktly follow the below answer format:\\nvalue\\n26+15+24-4-6-12 = 43\\n43'}]\n",
      "\n",
      "Prompt 2, Question 18\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "```\n",
      "24\n",
      "```\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nIt takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\\nStricktly follow the below answer format:\\nvalue\\n```\\n24\\n```'}]\n",
      "\n",
      "Prompt 2, Question 19\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "Stricktly follow the below answer format:\n",
      "value\n",
      "Answer:\n",
      "16.8\n",
      "\n",
      "[{'generated_text': 'Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\nTim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\\nStricktly follow the below answer format:\\nvalue\\nAnswer:\\n16.8\\n'}]\n",
      "\n",
      "Prompt 3, Question 0\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "72\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n72\\n'}]\n",
      "\n",
      "Prompt 3, Question 1\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "10\n",
      "\n",
      "Final Answer: The final answer is $\\boxed{10}$\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nWeng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n10\\n\\nFinal Answer: The final answer is $\\\\boxed{10}$'}]\n",
      "\n",
      "Prompt 3, Question 2\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "\n",
      "35\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nBetty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n\\n35\\n'}]\n",
      "\n",
      "Prompt 3, Question 3\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "30\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJulie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n30\\n'}]\n",
      "\n",
      "Prompt 3, Question 4\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "312\n",
      "The question is asking for the final answer only.\n",
      "312\n",
      "Correct.\n",
      "Final Answer: 312\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJames writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n312\\nThe question is asking for the final answer only.\\n312\\nCorrect.\\nFinal Answer: 312'}]\n",
      "\n",
      "Prompt 3, Question 5\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "125\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nMark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n125\\n'}]\n",
      "\n",
      "Prompt 3, Question 6\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "56\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nAlbert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n56\\n'}]\n",
      "\n",
      "Prompt 3, Question 7\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "32\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nKen created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n32\\n'}]\n",
      "\n",
      "Prompt 3, Question 8\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "$107\n",
      "$114\n",
      "$117\n",
      "$127\n",
      "$137\n",
      "$107\n",
      "$114\n",
      "$117\n",
      "$127\n",
      "$137\n",
      "$114\n",
      "$114\n",
      "$107\n",
      "$114\n",
      "$107\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "$114\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nAlexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n$107\\n$114\\n$117\\n$127\\n$137\\n$107\\n$114\\n$117\\n$127\\n$137\\n$114\\n$114\\n$107\\n$114\\n$107\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114\\n$114'}]\n",
      "\n",
      "Prompt 3, Question 9\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "900\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n900\\n'}]\n",
      "\n",
      "Prompt 3, Question 10\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "16\n",
      "\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nA deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n16\\n\\n'}]\n",
      "\n",
      "Prompt 3, Question 11\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "5\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n5\\n'}]\n",
      "\n",
      "Prompt 3, Question 12\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "105\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nRandy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n105'}]\n",
      "\n",
      "Prompt 3, Question 13\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "$26\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n$26\\n'}]\n",
      "\n",
      "Prompt 3, Question 14\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "\n",
      "1.5\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJoy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n\\n1.5\\n'}]\n",
      "\n",
      "Prompt 3, Question 15\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "$235000\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJames creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n$235000\\n'}]\n",
      "\n",
      "Prompt 3, Question 16\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "2300\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nThe profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n2300\\n'}]\n",
      "\n",
      "Prompt 3, Question 17\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "79\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nIn a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n79'}]\n",
      "\n",
      "Prompt 3, Question 18\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "14\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nIt takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n14\\n'}]\n",
      "\n",
      "Prompt 3, Question 19\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "I repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\n",
      "26.4\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\\n26.4\\n'}]\n",
      "\n",
      "Prompt 4, Question 0\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "72\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n72\\n'}]\n",
      "\n",
      "Prompt 4, Question 1\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "10\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nWeng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n10\\n'}]\n",
      "\n",
      "Prompt 4, Question 2\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "40\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nBetty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n40\\n'}]\n",
      "\n",
      "Prompt 4, Question 3\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "30\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJulie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n30'}]\n",
      "\n",
      "Prompt 4, Question 4\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "312\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJames writes a 3-page letter to 2 different friends twice a week.  How many pages does he write a year?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n312\\n'}]\n",
      "\n",
      "Prompt 4, Question 5\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Mark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "132\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nMark has a garden with flowers. He planted plants of three different colors in it. Ten of them are yellow, and there are 80% more of those in purple. There are only 25% as many green flowers as there are yellow and purple flowers. How many flowers does Mark have in his garden?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n132\\n'}]\n",
      "\n",
      "Prompt 4, Question 6\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Albert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "56\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nAlbert is wondering how much pizza he can eat in one day. He buys 2 large pizzas and 2 small pizzas. A large pizza has 16 slices and a small pizza has 8 slices. If he eats it all, how many pieces does he eat that day?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n56\\n'}]\n",
      "\n",
      "Prompt 4, Question 7\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Ken created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "24\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nKen created a care package to send to his brother, who was away at boarding school.  Ken placed a box on a scale, and then he poured into the box enough jelly beans to bring the weight to 2 pounds.  Then, he added enough brownies to cause the weight to triple.  Next, he added another 2 pounds of jelly beans.  And finally, he added enough gummy worms to double the weight once again.  What was the final weight of the box of goodies, in pounds?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n24\\n'}]\n",
      "\n",
      "Prompt 4, Question 8\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Alexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "127\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nAlexis is applying for a new job and bought a new set of business clothes to wear to the interview. She went to a department store with a budget of $200 and spent $30 on a button-up shirt, $46 on suit pants, $38 on a suit coat, $11 on socks, and $18 on a belt. She also purchased a pair of shoes, but lost the receipt for them. She has $16 left from her budget. How much did Alexis pay for the shoes?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n\\n127\\n'}]\n",
      "\n",
      "Prompt 4, Question 9\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "900\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTina makes $18.00 an hour.  If she works more than 8 hours per shift, she is eligible for overtime, which is paid by your hourly wage + 1/2 your hourly wage.  If she works 10 hours every day for 5 days, how much money does she make?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n900\\n'}]\n",
      "\n",
      "Prompt 4, Question 10\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "A deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "\n",
      "14\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nA deep-sea monster rises from the waters once every hundred years to feast on a ship and sate its hunger. Over three hundred years, it has consumed 847 people. Ships have been built larger over time, so each new ship has twice as many people as the last ship. How many people were on the ship the monster ate in the first hundred years?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n\\n14\\n'}]\n",
      "\n",
      "Prompt 4, Question 11\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "10\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTobias is buying a new pair of shoes that costs $95. He has been saving up his money each month for the past three months. He gets a $5 allowance a month. He also mows lawns and shovels driveways. He charges $15 to mow a lawn and $7 to shovel. After buying the shoes, he has $15 in change. If he mows 4 lawns, how many driveways did he shovel?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n10'}]\n",
      "\n",
      "Prompt 4, Question 12\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "115\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nRandy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n115\\n'}]\n",
      "\n",
      "Prompt 4, Question 13\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Jasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "32\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJasper will serve charcuterie at his dinner party. He buys 2 pounds of cheddar cheese for $10, a pound of cream cheese that cost half the price of the cheddar cheese, and a pack of cold cuts that cost twice the price of the cheddar cheese. How much does he spend on the ingredients?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n32\\n'}]\n",
      "\n",
      "Prompt 4, Question 14\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Joy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "5\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJoy can read 8 pages of a book in 20 minutes. How many hours will it take her to read 120 pages?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n5\\n'}]\n",
      "\n",
      "Prompt 4, Question 15\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "James creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "158000\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nJames creates a media empire.  He creates a movie for $2000.  Each DVD cost $6 to make.  He sells it for 2.5 times that much.  He sells 500 movies a day for 5 days a week.  How much profit does he make in 20 weeks?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n158000\\n'}]\n",
      "\n",
      "Prompt 4, Question 16\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "The profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "1400\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nThe profit from a business transaction is shared among 2 business partners, Mike and Johnson in the ratio 2:5 respectively. If Johnson got $2500, how much will Mike have after spending some of his share on a shirt that costs $200?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n1400\\n'}]\n",
      "\n",
      "Prompt 4, Question 17\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "In a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "77\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nIn a truck, there are 26 pink hard hats, 15 green hard hats, and 24 yellow hard hats.  If Carl takes away 4 pink hard hats, and John takes away 6 pink hard hats and twice as many green hard hats as the number of pink hard hats that he removed, then calculate the total number of hard hats that remained in the truck.\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n77'}]\n",
      "\n",
      "Prompt 4, Question 18\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "It takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "16\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nIt takes Roque two hours to walk to work and one hour to ride his bike to work. Roque walks to and from work three times a week and rides his bike to and from work twice a week. How many hours in total does he take to get to and from work a week with walking and biking?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n16\\n'}]\n",
      "\n",
      "Prompt 4, Question 19\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Tim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\n",
      "I repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\n",
      "24\n",
      "\n",
      "[{'generated_text': 'Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nTim rides his bike back and forth to work for each of his 5 workdays.  His work is 20 miles away.  He also goes for a weekend bike ride of 200 miles.    If he can bike at 25 mph how much time does he spend biking a week?\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\\n24\\n'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# Model name\n",
    "model_name = \"google/gemma-3-12b-it\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     device_map=\"auto\",       # Automatically put model on available GPUs\n",
    "#     torch_dtype=\"auto\"       # Optional: use bf16/fp16 if supported\n",
    "# )\n",
    "\n",
    "# Create inference pipeline\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# # Prompt (use instruction-style prompting)\n",
    "# prompt = \"Write a short story about a robot who learns to paint.\"\n",
    "\n",
    "# # Generate output\n",
    "# outputs = generator(prompt, max_new_tokens=500, do_sample=True, temperature=0.7)\n",
    "\n",
    "# # Print result\n",
    "# print(outputs[0][\"generated_text\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# prompts = [\n",
    "#     \"Answer the following question. Explain your reasoning step by step. After your reasoning, state the single correct numerical value (int), no other symbols, only one integer for the answer on a new line, prefixed with '### Answer:'.\\n{question}\",\n",
    "#     \"Answer the following question, by explaining your reasoning step-by-step in a single paragraph to determine the correct answer for the following question. After your reasoning, state the single correct numerical value (int), no other symbols, only one integer for the answer on a new line, prefixed with '### Answer:'.\\n{question}\",\n",
    "# ]\n",
    "\n",
    "prompts = [\n",
    "    \"Answer this question strictly with the final numerical value. No words, steps, or additional text allowed.\\n{question}\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\",\n",
    "    \"Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\n{question}\\nStricktly follow the below answer format:\\nvalue\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\",\n",
    "    \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\",\n",
    "]\n",
    "\n",
    "# estimator = MaximumSequenceProbability()\n",
    "results = []\n",
    "\n",
    "for i in range(2, len(prompts)):\n",
    "    # Replace {question} in the prompt for each of the first 5 questions\n",
    "    for j in range(20):\n",
    "        question = gsm8k_df['question'].iloc[j]\n",
    "        prompt_text = prompts[i].replace(\"{question}\", question)\n",
    "\n",
    "        # Estimate uncertainty\n",
    "        outputs = generator(prompt_text, max_new_tokens=500, do_sample=True, temperature=0.7)\n",
    "\n",
    "        # Collect result\n",
    "        results.append({\n",
    "            \"prompt_index\": i,\n",
    "            \"question_index\": j,\n",
    "            \"input_text\": prompt_text,\n",
    "            \"generation_text\": outputs[0][\"generated_text\"],\n",
    "            \"ground_truth\": gsm8k_df['short_answer'].iloc[j],\n",
    "            \"all\": outputs\n",
    "        })\n",
    "\n",
    "        # Optionally print\n",
    "        print(f\"Prompt {i}, Question {j}\")\n",
    "        print(prompt_text)\n",
    "        print(outputs[0][\"generated_text\"])\n",
    "        print(outputs)\n",
    "        print()\n",
    "\n",
    "\n",
    "# Convert new results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "try:\n",
    "    # Load existing results\n",
    "    dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}_2.csv')\n",
    "    # Append new results\n",
    "    combined_df = pd.concat([dftemp, results_df], ignore_index=True)\n",
    "    # Save the combined DataFrame back to CSV\n",
    "    combined_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}_2.csv', index=False)\n",
    "except:\n",
    "    results_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa58b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsm8k_gemma-3-12b-it_cot.csv\n",
      "\n",
      "Average Output Length (Characters) per Prompt:\n",
      "Prompt 0: 20.00 characters\n",
      "Prompt 1: 20.00 characters\n"
     ]
    }
   ],
   "source": [
    "dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv')\n",
    "dftemp['extracted_answer'] = dftemp['generation_text'].str.extract(r'### Answer:\\s*(.*)', expand=False)\n",
    "\n",
    "print(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv\\n')\n",
    "# Group by prompt index and compute average output length (in characters)\n",
    "non_null_counts = dftemp.groupby(\"prompt_index\")['extracted_answer'].count()\n",
    "\n",
    "print(\"Average Output Length (Characters) per Prompt:\")\n",
    "for i, avg_len in non_null_counts.items():\n",
    "    print(f\"Prompt {i}: {avg_len:.2f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb32976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Output Length (Characters) per Prompt:\n",
      "Prompt 2: 12.75 characters\n",
      "Prompt 3: 35.90 characters\n",
      "Prompt 4: 4.45 characters\n",
      "\n",
      "Median Output Length (Characters) per Prompt:\n",
      "Prompt 2: 12.0 characters\n",
      "Prompt 3: 5.0 characters\n",
      "Prompt 4: 4.0 characters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}.csv')\n",
    "dftemp = pd.read_csv(f'gsm8k_Llama-3.1-8B-Instruct.csv')\n",
    "dftemp = pd.read_csv(f'gsm8k_gemma-3-12b-it_2.csv')\n",
    "\n",
    "\n",
    "def extract_output(generation, input_text):\n",
    "    # Split the generation using the input text\n",
    "    if input_text in generation:\n",
    "        return generation.split(input_text, 1)[1]  # return only the part after the input\n",
    "    else:\n",
    "        return generation  # fallback if input_text is not found\n",
    "\n",
    "# Apply the function row-wise and compute output length\n",
    "dftemp['extracted_output'] = dftemp.apply(lambda row: extract_output(row['generation_text'], row['input_text']), axis=1)\n",
    "dftemp['output_length_chars'] = dftemp['extracted_output'].apply(len)\n",
    "\n",
    "\n",
    "\n",
    "# print(f'gsm8k_{model_name.split(\"/\")[1]}.csv\\n')\n",
    "# Group by prompt index and compute average output length (in characters)\n",
    "avg_lengths = dftemp.groupby(\"prompt_index\")['output_length_chars'].mean()\n",
    "\n",
    "print(\"Average Output Length (Characters) per Prompt:\")\n",
    "for i, avg_len in avg_lengths.items():\n",
    "    print(f\"Prompt {i}: {avg_len:.2f} characters\")\n",
    "\n",
    "# Group by prompt and compute median character length\n",
    "median_lengths_chars = dftemp.groupby(\"prompt_index\")['output_length_chars'].median()\n",
    "\n",
    "print()\n",
    "print(\"Median Output Length (Characters) per Prompt:\")\n",
    "for i, median_len in median_lengths_chars.items():\n",
    "    print(f\"Prompt {i}: {median_len} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1df3755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>question_index</th>\n",
       "      <th>input_text</th>\n",
       "      <th>generation_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>all</th>\n",
       "      <th>extracted_output</th>\n",
       "      <th>output_length_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>72</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n120\\n```</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n10\\n```\\n10\\n```\\n10\\n```</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n100\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>42</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n30\\n```</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>624</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n1056\\n```</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n189\\n```</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>48</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n56\\n```</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n10\\n```\\n16\\n```</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>41</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n67\\n```</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>990</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n1170\\n```</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>121</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n148\\n```</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n11\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>85</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n115\\n```</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n32\\n```</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n2.5\\n```</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>448000</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n115000\\n```</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>800</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n4800\\n```</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>43</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n26+15+24-4-6-12 = 43\\n43</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n```\\n24\\n```</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>Answer the following question. Provide only th...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\nAnswer:\\n16.8\\n</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>72</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n72\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n10\\n\\nFinal Answer: The final answer is $\\bo...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n\\n35\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>42</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n30\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>624</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n312\\nThe question is asking for the final an...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n125\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>48</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n56\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n32\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>41</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n$107\\n$114\\n$117\\n$127\\n$137\\n$107\\n$114\\n$1...</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>990</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n900\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>121</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n16\\n\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n5\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>85</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n$26\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n\\n1.5\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>448000</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n$235000\\n</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>800</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n2300\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>43</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n79</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n14\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n26.4\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>72</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n72\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n10\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n40\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>42</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>624</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n312\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n132\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>48</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n56\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n24\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>41</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n\\n127\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>990</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n900\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>121</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n\\n14\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>85</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n115\\n</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>35</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n32\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n5\\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>448000</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n158000\\n</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>800</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n1400\\n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>43</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n16\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>16</td>\n",
       "      <td>[{'generated_text': 'Answer the following ques...</td>\n",
       "      <td>\\n24\\n</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_index  question_index  \\\n",
       "0              2               0   \n",
       "1              2               1   \n",
       "2              2               2   \n",
       "3              2               3   \n",
       "4              2               4   \n",
       "5              2               5   \n",
       "6              2               6   \n",
       "7              2               7   \n",
       "8              2               8   \n",
       "9              2               9   \n",
       "10             2              10   \n",
       "11             2              11   \n",
       "12             2              12   \n",
       "13             2              13   \n",
       "14             2              14   \n",
       "15             2              15   \n",
       "16             2              16   \n",
       "17             2              17   \n",
       "18             2              18   \n",
       "19             2              19   \n",
       "20             3               0   \n",
       "21             3               1   \n",
       "22             3               2   \n",
       "23             3               3   \n",
       "24             3               4   \n",
       "25             3               5   \n",
       "26             3               6   \n",
       "27             3               7   \n",
       "28             3               8   \n",
       "29             3               9   \n",
       "30             3              10   \n",
       "31             3              11   \n",
       "32             3              12   \n",
       "33             3              13   \n",
       "34             3              14   \n",
       "35             3              15   \n",
       "36             3              16   \n",
       "37             3              17   \n",
       "38             3              18   \n",
       "39             3              19   \n",
       "40             4               0   \n",
       "41             4               1   \n",
       "42             4               2   \n",
       "43             4               3   \n",
       "44             4               4   \n",
       "45             4               5   \n",
       "46             4               6   \n",
       "47             4               7   \n",
       "48             4               8   \n",
       "49             4               9   \n",
       "50             4              10   \n",
       "51             4              11   \n",
       "52             4              12   \n",
       "53             4              13   \n",
       "54             4              14   \n",
       "55             4              15   \n",
       "56             4              16   \n",
       "57             4              17   \n",
       "58             4              18   \n",
       "59             4              19   \n",
       "\n",
       "                                           input_text  \\\n",
       "0   Answer the following question. Provide only th...   \n",
       "1   Answer the following question. Provide only th...   \n",
       "2   Answer the following question. Provide only th...   \n",
       "3   Answer the following question. Provide only th...   \n",
       "4   Answer the following question. Provide only th...   \n",
       "5   Answer the following question. Provide only th...   \n",
       "6   Answer the following question. Provide only th...   \n",
       "7   Answer the following question. Provide only th...   \n",
       "8   Answer the following question. Provide only th...   \n",
       "9   Answer the following question. Provide only th...   \n",
       "10  Answer the following question. Provide only th...   \n",
       "11  Answer the following question. Provide only th...   \n",
       "12  Answer the following question. Provide only th...   \n",
       "13  Answer the following question. Provide only th...   \n",
       "14  Answer the following question. Provide only th...   \n",
       "15  Answer the following question. Provide only th...   \n",
       "16  Answer the following question. Provide only th...   \n",
       "17  Answer the following question. Provide only th...   \n",
       "18  Answer the following question. Provide only th...   \n",
       "19  Answer the following question. Provide only th...   \n",
       "20  Answer the following question, by giving only ...   \n",
       "21  Answer the following question, by giving only ...   \n",
       "22  Answer the following question, by giving only ...   \n",
       "23  Answer the following question, by giving only ...   \n",
       "24  Answer the following question, by giving only ...   \n",
       "25  Answer the following question, by giving only ...   \n",
       "26  Answer the following question, by giving only ...   \n",
       "27  Answer the following question, by giving only ...   \n",
       "28  Answer the following question, by giving only ...   \n",
       "29  Answer the following question, by giving only ...   \n",
       "30  Answer the following question, by giving only ...   \n",
       "31  Answer the following question, by giving only ...   \n",
       "32  Answer the following question, by giving only ...   \n",
       "33  Answer the following question, by giving only ...   \n",
       "34  Answer the following question, by giving only ...   \n",
       "35  Answer the following question, by giving only ...   \n",
       "36  Answer the following question, by giving only ...   \n",
       "37  Answer the following question, by giving only ...   \n",
       "38  Answer the following question, by giving only ...   \n",
       "39  Answer the following question, by giving only ...   \n",
       "40  Answer the following question, by giving only ...   \n",
       "41  Answer the following question, by giving only ...   \n",
       "42  Answer the following question, by giving only ...   \n",
       "43  Answer the following question, by giving only ...   \n",
       "44  Answer the following question, by giving only ...   \n",
       "45  Answer the following question, by giving only ...   \n",
       "46  Answer the following question, by giving only ...   \n",
       "47  Answer the following question, by giving only ...   \n",
       "48  Answer the following question, by giving only ...   \n",
       "49  Answer the following question, by giving only ...   \n",
       "50  Answer the following question, by giving only ...   \n",
       "51  Answer the following question, by giving only ...   \n",
       "52  Answer the following question, by giving only ...   \n",
       "53  Answer the following question, by giving only ...   \n",
       "54  Answer the following question, by giving only ...   \n",
       "55  Answer the following question, by giving only ...   \n",
       "56  Answer the following question, by giving only ...   \n",
       "57  Answer the following question, by giving only ...   \n",
       "58  Answer the following question, by giving only ...   \n",
       "59  Answer the following question, by giving only ...   \n",
       "\n",
       "                                      generation_text  ground_truth  \\\n",
       "0   Answer the following question. Provide only th...            72   \n",
       "1   Answer the following question. Provide only th...            10   \n",
       "2   Answer the following question. Provide only th...             5   \n",
       "3   Answer the following question. Provide only th...            42   \n",
       "4   Answer the following question. Provide only th...           624   \n",
       "5   Answer the following question. Provide only th...            35   \n",
       "6   Answer the following question. Provide only th...            48   \n",
       "7   Answer the following question. Provide only th...            16   \n",
       "8   Answer the following question. Provide only th...            41   \n",
       "9   Answer the following question. Provide only th...           990   \n",
       "10  Answer the following question. Provide only th...           121   \n",
       "11  Answer the following question. Provide only th...             5   \n",
       "12  Answer the following question. Provide only th...            85   \n",
       "13  Answer the following question. Provide only th...            35   \n",
       "14  Answer the following question. Provide only th...             5   \n",
       "15  Answer the following question. Provide only th...        448000   \n",
       "16  Answer the following question. Provide only th...           800   \n",
       "17  Answer the following question. Provide only th...            43   \n",
       "18  Answer the following question. Provide only th...            16   \n",
       "19  Answer the following question. Provide only th...            16   \n",
       "20  Answer the following question, by giving only ...            72   \n",
       "21  Answer the following question, by giving only ...            10   \n",
       "22  Answer the following question, by giving only ...             5   \n",
       "23  Answer the following question, by giving only ...            42   \n",
       "24  Answer the following question, by giving only ...           624   \n",
       "25  Answer the following question, by giving only ...            35   \n",
       "26  Answer the following question, by giving only ...            48   \n",
       "27  Answer the following question, by giving only ...            16   \n",
       "28  Answer the following question, by giving only ...            41   \n",
       "29  Answer the following question, by giving only ...           990   \n",
       "30  Answer the following question, by giving only ...           121   \n",
       "31  Answer the following question, by giving only ...             5   \n",
       "32  Answer the following question, by giving only ...            85   \n",
       "33  Answer the following question, by giving only ...            35   \n",
       "34  Answer the following question, by giving only ...             5   \n",
       "35  Answer the following question, by giving only ...        448000   \n",
       "36  Answer the following question, by giving only ...           800   \n",
       "37  Answer the following question, by giving only ...            43   \n",
       "38  Answer the following question, by giving only ...            16   \n",
       "39  Answer the following question, by giving only ...            16   \n",
       "40  Answer the following question, by giving only ...            72   \n",
       "41  Answer the following question, by giving only ...            10   \n",
       "42  Answer the following question, by giving only ...             5   \n",
       "43  Answer the following question, by giving only ...            42   \n",
       "44  Answer the following question, by giving only ...           624   \n",
       "45  Answer the following question, by giving only ...            35   \n",
       "46  Answer the following question, by giving only ...            48   \n",
       "47  Answer the following question, by giving only ...            16   \n",
       "48  Answer the following question, by giving only ...            41   \n",
       "49  Answer the following question, by giving only ...           990   \n",
       "50  Answer the following question, by giving only ...           121   \n",
       "51  Answer the following question, by giving only ...             5   \n",
       "52  Answer the following question, by giving only ...            85   \n",
       "53  Answer the following question, by giving only ...            35   \n",
       "54  Answer the following question, by giving only ...             5   \n",
       "55  Answer the following question, by giving only ...        448000   \n",
       "56  Answer the following question, by giving only ...           800   \n",
       "57  Answer the following question, by giving only ...            43   \n",
       "58  Answer the following question, by giving only ...            16   \n",
       "59  Answer the following question, by giving only ...            16   \n",
       "\n",
       "                                                  all  \\\n",
       "0   [{'generated_text': 'Answer the following ques...   \n",
       "1   [{'generated_text': 'Answer the following ques...   \n",
       "2   [{'generated_text': 'Answer the following ques...   \n",
       "3   [{'generated_text': 'Answer the following ques...   \n",
       "4   [{'generated_text': 'Answer the following ques...   \n",
       "5   [{'generated_text': 'Answer the following ques...   \n",
       "6   [{'generated_text': 'Answer the following ques...   \n",
       "7   [{'generated_text': 'Answer the following ques...   \n",
       "8   [{'generated_text': 'Answer the following ques...   \n",
       "9   [{'generated_text': 'Answer the following ques...   \n",
       "10  [{'generated_text': 'Answer the following ques...   \n",
       "11  [{'generated_text': 'Answer the following ques...   \n",
       "12  [{'generated_text': 'Answer the following ques...   \n",
       "13  [{'generated_text': 'Answer the following ques...   \n",
       "14  [{'generated_text': 'Answer the following ques...   \n",
       "15  [{'generated_text': 'Answer the following ques...   \n",
       "16  [{'generated_text': 'Answer the following ques...   \n",
       "17  [{'generated_text': 'Answer the following ques...   \n",
       "18  [{'generated_text': 'Answer the following ques...   \n",
       "19  [{'generated_text': 'Answer the following ques...   \n",
       "20  [{'generated_text': 'Answer the following ques...   \n",
       "21  [{'generated_text': 'Answer the following ques...   \n",
       "22  [{'generated_text': 'Answer the following ques...   \n",
       "23  [{'generated_text': 'Answer the following ques...   \n",
       "24  [{'generated_text': 'Answer the following ques...   \n",
       "25  [{'generated_text': 'Answer the following ques...   \n",
       "26  [{'generated_text': 'Answer the following ques...   \n",
       "27  [{'generated_text': 'Answer the following ques...   \n",
       "28  [{'generated_text': 'Answer the following ques...   \n",
       "29  [{'generated_text': 'Answer the following ques...   \n",
       "30  [{'generated_text': 'Answer the following ques...   \n",
       "31  [{'generated_text': 'Answer the following ques...   \n",
       "32  [{'generated_text': 'Answer the following ques...   \n",
       "33  [{'generated_text': 'Answer the following ques...   \n",
       "34  [{'generated_text': 'Answer the following ques...   \n",
       "35  [{'generated_text': 'Answer the following ques...   \n",
       "36  [{'generated_text': 'Answer the following ques...   \n",
       "37  [{'generated_text': 'Answer the following ques...   \n",
       "38  [{'generated_text': 'Answer the following ques...   \n",
       "39  [{'generated_text': 'Answer the following ques...   \n",
       "40  [{'generated_text': 'Answer the following ques...   \n",
       "41  [{'generated_text': 'Answer the following ques...   \n",
       "42  [{'generated_text': 'Answer the following ques...   \n",
       "43  [{'generated_text': 'Answer the following ques...   \n",
       "44  [{'generated_text': 'Answer the following ques...   \n",
       "45  [{'generated_text': 'Answer the following ques...   \n",
       "46  [{'generated_text': 'Answer the following ques...   \n",
       "47  [{'generated_text': 'Answer the following ques...   \n",
       "48  [{'generated_text': 'Answer the following ques...   \n",
       "49  [{'generated_text': 'Answer the following ques...   \n",
       "50  [{'generated_text': 'Answer the following ques...   \n",
       "51  [{'generated_text': 'Answer the following ques...   \n",
       "52  [{'generated_text': 'Answer the following ques...   \n",
       "53  [{'generated_text': 'Answer the following ques...   \n",
       "54  [{'generated_text': 'Answer the following ques...   \n",
       "55  [{'generated_text': 'Answer the following ques...   \n",
       "56  [{'generated_text': 'Answer the following ques...   \n",
       "57  [{'generated_text': 'Answer the following ques...   \n",
       "58  [{'generated_text': 'Answer the following ques...   \n",
       "59  [{'generated_text': 'Answer the following ques...   \n",
       "\n",
       "                                     extracted_output  output_length_chars  \n",
       "0                                     \\n```\\n120\\n```                   12  \n",
       "1                    \\n```\\n10\\n```\\n10\\n```\\n10\\n```                   25  \n",
       "2                                             \\n100\\n                    5  \n",
       "3                                      \\n```\\n30\\n```                   11  \n",
       "4                                    \\n```\\n1056\\n```                   13  \n",
       "5                                     \\n```\\n189\\n```                   12  \n",
       "6                                      \\n```\\n56\\n```                   11  \n",
       "7                                  \\n10\\n```\\n16\\n```                   14  \n",
       "8                                      \\n```\\n67\\n```                   11  \n",
       "9                                    \\n```\\n1170\\n```                   13  \n",
       "10                                    \\n```\\n148\\n```                   12  \n",
       "11                                             \\n11\\n                    4  \n",
       "12                                    \\n```\\n115\\n```                   12  \n",
       "13                                     \\n```\\n32\\n```                   11  \n",
       "14                                    \\n```\\n2.5\\n```                   12  \n",
       "15                                 \\n```\\n115000\\n```                   15  \n",
       "16                                   \\n```\\n4800\\n```                   13  \n",
       "17                         \\n26+15+24-4-6-12 = 43\\n43                   24  \n",
       "18                                     \\n```\\n24\\n```                   11  \n",
       "19                                  \\nAnswer:\\n16.8\\n                   14  \n",
       "20                                             \\n72\\n                    4  \n",
       "21  \\n10\\n\\nFinal Answer: The final answer is $\\bo...                   51  \n",
       "22                                           \\n\\n35\\n                    5  \n",
       "23                                             \\n30\\n                    4  \n",
       "24  \\n312\\nThe question is asking for the final an...                   85  \n",
       "25                                            \\n125\\n                    5  \n",
       "26                                             \\n56\\n                    4  \n",
       "27                                             \\n32\\n                    4  \n",
       "28  \\n$107\\n$114\\n$117\\n$127\\n$137\\n$107\\n$114\\n$1...                  500  \n",
       "29                                            \\n900\\n                    5  \n",
       "30                                           \\n16\\n\\n                    5  \n",
       "31                                              \\n5\\n                    3  \n",
       "32                                              \\n105                    4  \n",
       "33                                            \\n$26\\n                    5  \n",
       "34                                          \\n\\n1.5\\n                    6  \n",
       "35                                        \\n$235000\\n                    9  \n",
       "36                                           \\n2300\\n                    6  \n",
       "37                                               \\n79                    3  \n",
       "38                                             \\n14\\n                    4  \n",
       "39                                           \\n26.4\\n                    6  \n",
       "40                                             \\n72\\n                    4  \n",
       "41                                             \\n10\\n                    4  \n",
       "42                                             \\n40\\n                    4  \n",
       "43                                               \\n30                    3  \n",
       "44                                            \\n312\\n                    5  \n",
       "45                                            \\n132\\n                    5  \n",
       "46                                             \\n56\\n                    4  \n",
       "47                                             \\n24\\n                    4  \n",
       "48                                          \\n\\n127\\n                    6  \n",
       "49                                            \\n900\\n                    5  \n",
       "50                                           \\n\\n14\\n                    5  \n",
       "51                                               \\n10                    3  \n",
       "52                                            \\n115\\n                    5  \n",
       "53                                             \\n32\\n                    4  \n",
       "54                                              \\n5\\n                    3  \n",
       "55                                         \\n158000\\n                    8  \n",
       "56                                           \\n1400\\n                    6  \n",
       "57                                               \\n77                    3  \n",
       "58                                             \\n16\\n                    4  \n",
       "59                                             \\n24\\n                    4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "852ac466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    1\n",
       "14    1\n",
       "15    1\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    1\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "30    0\n",
       "31    0\n",
       "32    0\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "36    0\n",
       "37    0\n",
       "38    0\n",
       "39    0\n",
       "Name: prompt_index, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv(\"gsm8k_deepseek-llm-7b-chat_cot.csv\")\n",
    "dft = pd.read_csv(\"gsm8k_Llama-3.1-8B-Instruct_cot.csv\")\n",
    "dft = pd.read_csv(\"gsm8k_phi-4_cot.csv\")\n",
    "# dft = pd.read_csv(\"gsm8k_Qwen2.5-7B-Instruct_cot.csv\")\n",
    "\n",
    "dft['prompt_index']\n",
    "# dft = dft[:-20]  # Keeps all rows except the last 20\n",
    "\n",
    "# # Optionally, save it back\n",
    "# dft.to_csv('gsm8k_phi-4_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc349f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m prompts[i]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, question)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Estimate uncertainty\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m ans \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Collect result\u001b[39;00m\n\u001b[1;32m     46\u001b[0m results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: i,\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion_index\u001b[39m\u001b[38;5;124m\"\u001b[39m: j,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m: ans\n\u001b[1;32m     53\u001b[0m })\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/estimate_uncertainty.py:99\u001b[0m, in \u001b[0;36mestimate_uncertainty\u001b[0;34m(model, estimator, input_text)\u001b[0m\n\u001b[1;32m     84\u001b[0m     model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlackbox\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m man \u001b[38;5;241m=\u001b[39m UEManager(\n\u001b[1;32m     86\u001b[0m     Dataset([input_text], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m], batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     87\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     98\u001b[0m )\n\u001b[0;32m---> 99\u001b[0m \u001b[43mman\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m ue \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mestimations[estimator\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;28mstr\u001b[39m(estimator)]\n\u001b[1;32m    101\u001b[0m texts \u001b[38;5;241m=\u001b[39m man\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreedy_texts\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:404\u001b[0m, in \u001b[0;36mUEManager.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors:\n\u001b[1;32m    402\u001b[0m         processor\u001b[38;5;241m.\u001b[39mon_batch(batch_stats, batch_gen_metrics, batch_estimations)\n\u001b[0;32m--> 404\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_on_batch_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (gen_level, gen_name), generation_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ue_metric \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mue_metrics:\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:337\u001b[0m, in \u001b[0;36mUEManager._process\u001b[0;34m(self, iterable_data, batch_callback)\u001b[0m\n\u001b[1;32m    334\u001b[0m     batch_stats[key] \u001b[38;5;241m=\u001b[39m val\n\u001b[1;32m    335\u001b[0m batch_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m--> 337\u001b[0m batch_stats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat_calculators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m batch_estimations, bad_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate(\n\u001b[1;32m    340\u001b[0m     batch_stats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators\n\u001b[1;32m    341\u001b[0m )\n\u001b[1;32m    343\u001b[0m batch_callback(\n\u001b[1;32m    344\u001b[0m     batch_i, target_texts, batch_stats, batch_estimations, bad_estimators\n\u001b[1;32m    345\u001b[0m )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/manager.py:254\u001b[0m, in \u001b[0;36mUEManager.calculate\u001b[0;34m(self, batch_stats, calculators, inp_texts)\u001b[0m\n\u001b[1;32m    252\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    253\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m new_stats \u001b[38;5;241m=\u001b[39m \u001b[43mstat_calculator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minp_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_time:\n\u001b[1;32m    258\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone calculating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstat_calculator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m     )\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/stat_calculators/greedy_probs.py:78\u001b[0m, in \u001b[0;36mGreedyProbsCalculator.__call__\u001b[0;34m(self, dependencies, texts, model, max_new_tokens)\u001b[0m\n\u001b[1;32m     76\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 78\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_parameters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallow_newlines\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m                \u001b[49m\u001b[43mt\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(out\u001b[38;5;241m.\u001b[39mscores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvLLMCausalLM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/workspace/lm-polygraph/src/lm_polygraph/utils/model.py:535\u001b[0m, in \u001b[0;36mWhiteboxModel.generate\u001b[0;34m(self, **args)\u001b[0m\n\u001b[1;32m    532\u001b[0m args \u001b[38;5;241m=\u001b[39m default_params\n\u001b[1;32m    533\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args(args)\n\u001b[0;32m--> 535\u001b[0m generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# override generation.scores with original scores from model\u001b[39;00m\n\u001b[1;32m    538\u001b[0m generation\u001b[38;5;241m.\u001b[39mgeneration_scores \u001b[38;5;241m=\u001b[39m generation\u001b[38;5;241m.\u001b[39mscores\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/generation/utils.py:2597\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2589\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2590\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2591\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2592\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2593\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2594\u001b[0m     )\n\u001b[1;32m   2596\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2608\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2609\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2610\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2611\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2612\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2613\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2614\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/generation/utils.py:3560\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3560\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3562\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3563\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3564\u001b[0m     outputs,\n\u001b[1;32m   3565\u001b[0m     model_kwargs,\n\u001b[1;32m   3566\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3567\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:864\u001b[0m, in \u001b[0;36mGemma3ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m    860\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    861\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    862\u001b[0m )\n\u001b[1;32m    863\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/generic.py:969\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    971\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:654\u001b[0m, in \u001b[0;36mGemma3TextModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    642\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    643\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         cache_position,\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_global\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:463\u001b[0m, in \u001b[0;36mGemma3DecoderLayer.forward\u001b[0;34m(self, hidden_states, position_embeddings_global, position_embeddings_local, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m position_embeddings_global\n\u001b[0;32m--> 463\u001b[0m hidden_states, self_attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[1;32m    475\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:380\u001b[0m, in \u001b[0;36mGemma3Attention.forward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(query_states)\n\u001b[0;32m--> 380\u001b[0m attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    393\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mo_proj(attn_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:278\u001b[0m, in \u001b[0;36meager_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, softcap, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     scaling \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mhead_dim\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    277\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key, module\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[0;32m--> 278\u001b[0m value_states \u001b[38;5;241m=\u001b[39m \u001b[43mrepeat_kv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_key_value_groups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(query, key_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)) \u001b[38;5;241m*\u001b[39m scaling\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m softcap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/reasoning_uq/lib/python3.10/site-packages/transformers/models/gemma3/modeling_gemma3.py:260\u001b[0m, in \u001b[0;36mrepeat_kv\u001b[0;34m(hidden_states, n_rep)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n\u001b[1;32m    259\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, :, :]\u001b[38;5;241m.\u001b[39mexpand(batch, num_key_value_heads, n_rep, slen, head_dim)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_key_value_heads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# model_name = 'deepseek-ai/deepseek-llm-7b-chat'\n",
    "models = ['google/gemma-3-12b-it'] # 'google/gemma-3-12b-it', \n",
    "# 'google/gemma-3-12b-it'\n",
    "# 'deepseek-ai/deepseek-llm-7b-chat'\n",
    "# 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# 'microsoft/phi-4'\n",
    "# 'Qwen/Qwen2.5-7B-Instruct'\n",
    "\n",
    "for model_name in models:\n",
    "    # base_model = model\n",
    "    base_model = Gemma3ForCausalLM.from_pretrained( # Gemma3ForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        token=mytoken,\n",
    "        device_map='auto' # 'cpu',\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = WhiteboxModel(base_model, tokenizer)\n",
    "\n",
    "    prompts = [\n",
    "        \"Answer the following question. Explain your reasoning step by step. After your reasoning, state the single correct numerical value (int), no other symbols, only one integer for the answer on a new line, prefixed with '### Answer:'.\\n{question}\",\n",
    "        \"Answer the following question, by explaining your reasoning step-by-step in a single paragraph to determine the correct answer for the following question. After your reasoning, state the single correct numerical value (int), no other symbols, only one integer for the answer on a new line, prefixed with '### Answer:'.\\n{question}\",\n",
    "    # ]\n",
    "    # prompts = [\n",
    "    #     \"Answer this question strictly with the final numerical value. No words, steps, or additional text allowed.\\n{question}\",\n",
    "    #     \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\",\n",
    "    #     \"Answer the following question. Provide only the final numerical answer. Do not show any steps, explanations, or reasoning.\\n{question}\\nStricktly follow the below answer format:\\nvalue\",\n",
    "    #     \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value. Do not include any calculations or reasoning.\",\n",
    "    #     \"Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\n{question}\\nI repeat, the answer should only consist of the final numerical value (int), no other symbols, only one integer.\",\n",
    "    ]\n",
    "\n",
    "    estimator = MaximumSequenceProbability()\n",
    "    results = []\n",
    "\n",
    "    for i in range(0, 1): #len(prompts)):\n",
    "        # Replace {question} in the prompt for each of the first 5 questions\n",
    "        for j in range(2, 20):\n",
    "            question = gsm8k_df['question'].iloc[j]\n",
    "            prompt_text = prompts[i].replace(\"{question}\", question)\n",
    "\n",
    "            # Estimate uncertainty\n",
    "            ans = estimate_uncertainty(model, estimator, input_text=prompt_text)\n",
    "\n",
    "            # Collect result\n",
    "            results.append({\n",
    "                \"prompt_index\": i,\n",
    "                \"question_index\": j,\n",
    "                \"input_text\": ans.input_text,\n",
    "                \"generation_text\": ans.generation_text,\n",
    "                \"ground_truth\": gsm8k_df['short_answer'].iloc[j],\n",
    "                \"all\": ans\n",
    "            })\n",
    "\n",
    "            # Optionally print\n",
    "            print(f\"Prompt {i}, Question {j}\")\n",
    "            print(ans.input_text)\n",
    "            print(ans.generation_text)\n",
    "            print(ans)\n",
    "            print(len(ans.generation_tokens))\n",
    "            print()\n",
    "\n",
    "\n",
    "    # Convert new results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    try:\n",
    "        # Load existing results\n",
    "        dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv')\n",
    "        # Append new results\n",
    "        combined_df = pd.concat([dftemp, results_df], ignore_index=True)\n",
    "        # Save the combined DataFrame back to CSV\n",
    "        combined_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv', index=False)\n",
    "    except:\n",
    "        results_df.to_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea90008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>question_index</th>\n",
       "      <th>input_text</th>\n",
       "      <th>generation_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer the following question. Explain your re...</td>\n",
       "      <td>Here's how to solve the problem step-by-step:\\...</td>\n",
       "      <td>72</td>\n",
       "      <td>UncertaintyOutput(uncertainty=4.67648744583129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Answer the following question. Explain your re...</td>\n",
       "      <td>Here's how to solve the problem step-by-step:\\...</td>\n",
       "      <td>10</td>\n",
       "      <td>UncertaintyOutput(uncertainty=5.50194978713989...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt_index  question_index  \\\n",
       "0             0               0   \n",
       "1             0               1   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  Answer the following question. Explain your re...   \n",
       "1  Answer the following question. Explain your re...   \n",
       "\n",
       "                                     generation_text  ground_truth  \\\n",
       "0  Here's how to solve the problem step-by-step:\\...            72   \n",
       "1  Here's how to solve the problem step-by-step:\\...            10   \n",
       "\n",
       "                                                 all  \n",
       "0  UncertaintyOutput(uncertainty=4.67648744583129...  \n",
       "1  UncertaintyOutput(uncertainty=5.50194978713989...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv')\n",
    "dftemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f395eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsm8k_deepseek-llm-7b-chat_cot.csv\n",
      "\n",
      "Average Output Length (Characters) per Prompt:\n",
      "Prompt 0: 19.00 characters\n",
      "Prompt 1: 20.00 characters\n"
     ]
    }
   ],
   "source": [
    "dftemp = pd.read_csv(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv')\n",
    "dftemp['extracted_answer'] = dftemp['generation_text'].str.extract(r'### Answer:\\s*(.*)', expand=False)\n",
    "\n",
    "print(f'gsm8k_{model_name.split(\"/\")[1]}_cot.csv\\n')\n",
    "# Group by prompt index and compute average output length (in characters)\n",
    "non_null_counts = dftemp.groupby(\"prompt_index\")['extracted_answer'].count()\n",
    "\n",
    "print(\"Average Output Length (Characters) per Prompt:\")\n",
    "for i, avg_len in non_null_counts.items():\n",
    "    print(f\"Prompt {i}: {avg_len:.2f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043671a-939f-421b-b06b-24abf557fdc9",
   "metadata": {},
   "source": [
    "### Sequence-level UQ for a Whitebox LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6686143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_index</th>\n",
       "      <th>question_index</th>\n",
       "      <th>input_text</th>\n",
       "      <th>generation_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer this question strictly with the final n...</td>\n",
       "      <td>96&lt;end_of_turn&gt;</td>\n",
       "      <td>72</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.62811964750289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Answer this question strictly with the final n...</td>\n",
       "      <td>10\\n&lt;end_of_turn&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.00912463292479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Answer this question strictly with the final n...</td>\n",
       "      <td>20\\n&lt;end_of_turn&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.41650879383087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Answer this question strictly with the final n...</td>\n",
       "      <td>30&lt;end_of_turn&gt;</td>\n",
       "      <td>42</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.67018395662307...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Answer this question strictly with the final n...</td>\n",
       "      <td>1056&lt;end_of_turn&gt;</td>\n",
       "      <td>624</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.71765488386154...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>145000&lt;end_of_turn&gt;</td>\n",
       "      <td>448000</td>\n",
       "      <td>UncertaintyOutput(uncertainty=1.03194749355316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>1800&lt;end_of_turn&gt;</td>\n",
       "      <td>800</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.96552979946136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>65&lt;end_of_turn&gt;</td>\n",
       "      <td>43</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.36664539575576...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>20&lt;end_of_turn&gt;</td>\n",
       "      <td>16</td>\n",
       "      <td>UncertaintyOutput(uncertainty=0.38927680253982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>Answer the following question, by giving only ...</td>\n",
       "      <td>24&lt;end_of_turn&gt;</td>\n",
       "      <td>16</td>\n",
       "      <td>UncertaintyOutput(uncertainty=1.12019193172454...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prompt_index  question_index  \\\n",
       "0              0               0   \n",
       "1              0               1   \n",
       "2              0               2   \n",
       "3              0               3   \n",
       "4              0               4   \n",
       "..           ...             ...   \n",
       "95             4              15   \n",
       "96             4              16   \n",
       "97             4              17   \n",
       "98             4              18   \n",
       "99             4              19   \n",
       "\n",
       "                                           input_text      generation_text  \\\n",
       "0   Answer this question strictly with the final n...      96<end_of_turn>   \n",
       "1   Answer this question strictly with the final n...    10\\n<end_of_turn>   \n",
       "2   Answer this question strictly with the final n...    20\\n<end_of_turn>   \n",
       "3   Answer this question strictly with the final n...      30<end_of_turn>   \n",
       "4   Answer this question strictly with the final n...    1056<end_of_turn>   \n",
       "..                                                ...                  ...   \n",
       "95  Answer the following question, by giving only ...  145000<end_of_turn>   \n",
       "96  Answer the following question, by giving only ...    1800<end_of_turn>   \n",
       "97  Answer the following question, by giving only ...      65<end_of_turn>   \n",
       "98  Answer the following question, by giving only ...      20<end_of_turn>   \n",
       "99  Answer the following question, by giving only ...      24<end_of_turn>   \n",
       "\n",
       "    ground_truth                                                all  \n",
       "0             72  UncertaintyOutput(uncertainty=0.62811964750289...  \n",
       "1             10  UncertaintyOutput(uncertainty=0.00912463292479...  \n",
       "2              5  UncertaintyOutput(uncertainty=0.41650879383087...  \n",
       "3             42  UncertaintyOutput(uncertainty=0.67018395662307...  \n",
       "4            624  UncertaintyOutput(uncertainty=0.71765488386154...  \n",
       "..           ...                                                ...  \n",
       "95        448000  UncertaintyOutput(uncertainty=1.03194749355316...  \n",
       "96           800  UncertaintyOutput(uncertainty=0.96552979946136...  \n",
       "97            43  UncertaintyOutput(uncertainty=0.36664539575576...  \n",
       "98            16  UncertaintyOutput(uncertainty=0.38927680253982...  \n",
       "99            16  UncertaintyOutput(uncertainty=1.12019193172454...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gsm8k_gemma-3-12b-it.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687dd788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'lm_polygraph.utils.estimate_uncertainty.UncertaintyOutput'>\n",
      "UncertaintyOutput(uncertainty=22.52058219909668, input_text='Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\\nNatalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', generation_text='\\n\\nA. 48\\nB. 72\\nC. 96\\nD. 144\\n\\nSolution: The correct option is C 96\\n\\nTo find the total number of clips Natalia sold in April and May, we need to add the number of clips she sold in each month.\\n\\nIn April, Natalia sold 48 clips to her friends.\\n\\nIn May, she sold half as many clips as in April, which means she sold 48 / 2 = 24 clips.\\n\\n', generation_tokens=[198, 198, 32, 13, 4764, 198, 33, 13, 7724, 198, 34, 13, 9907, 198, 35, 13, 20224, 198, 198, 46344, 25, 383, 3376, 3038, 318, 327, 9907, 198, 198, 2514, 1064, 262, 2472, 1271, 286, 19166, 14393, 9752, 2702, 287, 3035, 290, 1737, 11, 356, 761, 284, 751, 262, 1271, 286, 19166, 673, 2702, 287, 1123, 1227, 13, 198, 198, 818, 3035, 11, 14393, 9752, 2702, 4764, 19166, 284, 607, 2460, 13, 198, 198, 818, 1737, 11, 673, 2702, 2063, 355, 867, 19166, 355, 287, 3035, 11, 543, 1724, 673, 2702, 4764, 1220, 362, 796, 1987, 19166, 13, 198], model_path=None, estimator='MaximumSequenceProbability')\n",
      "Answer the following question, by giving only the final answer, without any calculations, reasoning, or explanation.\n",
      "Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?\n",
      "answer: \n",
      "\n",
      "A. 48\n",
      "B. 72\n",
      "C. 96\n",
      "D. 144\n",
      "\n",
      "Solution: The correct option is C 96\n",
      "\n",
      "To find the total number of clips Natalia sold in April and May, we need to add the number of clips she sold in each month.\n",
      "\n",
      "In April, Natalia sold 48 clips to her friends.\n",
      "\n",
      "In May, she sold half as many clips as in April, which means she sold 48 / 2 = 24 clips.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimator = MaximumSequenceProbability()\n",
    "ans = estimate_uncertainty(model, estimator, input_text=gsm8k_df['short_question'].iloc[0])\n",
    "print(type(ans))\n",
    "print(ans)\n",
    "print(ans.input_text)\n",
    "print('answer:', ans.generation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061056eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=61.402503967285156, input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='MaximumSequenceProbability')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumSequenceProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a906db0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=99.17972927011878, input_text='How many floors are in the Empire State Building?', generation_text='The Empire State Building has 105 floors.', generation_tokens=[785, 20448, 3234, 16858, 702, 220, 16, 15, 20, 25945, 13], model_path=None, estimator='SemanticEntropy')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It takes 2 mins to run the example.\n",
    "\n",
    "estimator = SemanticEntropy()\n",
    "estimate_uncertainty(model, estimator, input_text='How many floors are in the Empire State Building?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2d94dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large-mnli were not used when initializing DebertaForSequenceClassification: ['config']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=115.85714697341697, input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='SemanticEntropy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It takes 2 mins to run the example.\n",
    "\n",
    "estimator = SemanticEntropy()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18648a-b1c7-4089-832e-84e17be8b203",
   "metadata": {},
   "source": [
    "### Token-level UQ for Whitebox LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247f5d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UncertaintyOutput(uncertainty=array([-0.5199645 , -0.7773075 , -0.9111757 , -0.4642391 , -0.7312121 ,\n",
       "       -0.96189463, -0.27488053, -0.11001918, -0.72922415, -0.43932858,\n",
       "       -0.99928606, -0.5605216 , -0.23990016, -0.7537944 , -0.24525657,\n",
       "       -0.6493522 , -0.99975866, -0.51964307, -0.8791548 , -0.21423468,\n",
       "       -0.35266286, -0.47724998, -0.45849365, -0.38198572, -0.8100885 ,\n",
       "       -0.6418665 , -0.7694248 , -0.30586314, -0.99927765, -0.9042026 ,\n",
       "       -0.87831134, -0.9398997 , -0.52133787, -0.5053506 , -0.9973978 ,\n",
       "       -0.67501503, -0.49679896, -0.7429459 , -0.35794568, -0.10462207,\n",
       "       -0.16433331, -0.5641733 , -0.80949354, -0.7477126 , -0.21802613,\n",
       "       -0.12109879, -0.6510552 , -0.2837354 , -0.2947866 , -0.98860633,\n",
       "       -0.5185005 , -0.1949296 , -0.51526326, -0.9765778 , -0.7364911 ,\n",
       "       -0.442843  , -0.2552529 , -0.9931718 , -0.49535578, -0.17133856,\n",
       "       -0.2405345 , -0.5826117 , -0.89956623, -0.22676547, -0.9783974 ,\n",
       "       -0.7804185 , -0.30011195, -0.541584  , -0.28006086, -0.5264636 ,\n",
       "       -0.96796274, -0.999999  , -0.5594297 , -0.44038415, -0.5604101 ,\n",
       "       -0.16485405, -0.99984914, -0.9997313 , -0.99999946, -0.23093723,\n",
       "       -0.29331768, -0.9013605 , -0.4138443 , -0.5036779 , -0.9412839 ,\n",
       "       -0.11232074, -0.9069531 ], dtype=float32), input_text='What has a head and a tail but no body?', generation_text=\"The answer to this question is a virus. Viruses are small, non-living entities that can only replicate within living cells. They do not have a head or a tail, but they can cause harm to living organisms by attaching to and hijacking the host cell's machinery. Viruses are a significant threat to public health and can cause a wide range of diseases, including but not limited to, influenza, HIV, and cancer.\", generation_tokens=[785, 4226, 311, 419, 3405, 374, 264, 16770, 13, 9542, 4776, 525, 2613, 11, 2477, 2852, 2249, 14744, 429, 646, 1172, 45013, 2878, 5382, 7761, 13, 2379, 653, 537, 614, 264, 1968, 476, 264, 9787, 11, 714, 807, 646, 5240, 11428, 311, 5382, 43204, 553, 71808, 311, 323, 21415, 8985, 279, 3468, 2779, 594, 25868, 13, 9542, 4776, 525, 264, 5089, 5899, 311, 584, 2820, 323, 646, 5240, 264, 6884, 2088, 315, 18808, 11, 2670, 714, 537, 7199, 311, 11, 61837, 11, 22664, 11, 323, 9387, 13], model_path=None, estimator='MaximumTokenProbability')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = MaximumTokenProbability()\n",
    "estimate_uncertainty(model, estimator, input_text='What has a head and a tail but no body?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reasoning_uq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
