hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: bloomz-560m
  - base_processing_triviaqa
  - default_estimators
  - default_calculators
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'
instruct: false
task: qa

dataset: [trivia_qa, rc.nocontext]
text_column: question
label_column: answer
description: ""
prompt: "Question: {question}\nAnswer:{answer}"
few_shot_prompt: null
few_shot_split: train
train_split: train
eval_split: validation
max_new_tokens: 20
load_from_disk: false
n_shot: 5
multiref: true
trust_remote_code: false
generation_params:
  generate_until:
    - "\n"

train_dataset: null
train_test_split: false
test_split_size: 1

background_train_dataset: allenai/c4
background_train_dataset_text_column: text
background_train_dataset_label_column: url
background_train_dataset_data_files: en/c4-train.00000-of-01024.json.gz
background_load_from_disk: false

subsample_background_train_dataset: 1000
subsample_train_dataset: 1000
subsample_eval_dataset: -1

generation_metrics: null

ignore_exceptions: false

batch_size: 2
deberta_batch_size: 10

seed:
    - 1
