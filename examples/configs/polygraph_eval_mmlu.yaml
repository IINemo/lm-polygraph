hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: bloomz-560m
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

task: qa

dataset: [cais/mmlu, all]
text_column: question
label_column: answer
description: "The following are multiple choice questions (with answers) about {subject}."
prompt: "Q:{question}\nA. {choices[0]}\nB. {choices[1]}\nC. {choices[2]}\nD. {choices[3]}\nAnswer:{answer}"
few_shot_split: dev
train_split: validation
eval_split: test
max_new_tokens: 3
load_from_disk: false
n_shot: 5
max_subject_size: 100
generation_params:
  generate_until:
    - "\n"

train_dataset: null
train_test_split: false
test_split_size: 1

background_train_dataset: allenai/c4
background_train_dataset_text_column: text
background_train_dataset_label_column: url
background_train_dataset_data_files: en/c4-train.00000-of-01024.json.gz
background_load_from_disk: false

subsample_background_train_dataset: 1000
subsample_train_dataset: 1000
subsample_eval_dataset: -1

use_density_based_ue: true
use_seq_ue: true
use_tok_ue: false
use_ens_ue: false
generation_metrics: null
ens_type: 

estimators:
  - name: MaximumSequenceProbability
  - name: MeanTokenEntropy
  - name: MahalanobisDistanceSeq
  - name: RelativeMahalanobisDistanceSeq
  - name: RDESeq
  - name: PPLMDSeq
    cfg:
      md_type: "MD"
  - name: PPLMDSeq
    cfg:
      md_type: "RMD"

stat_calculators:
  - auto
  - name: TrainingStatisticExtractionCalculator
    builder: lm_polygraph.defaults.stat_calculator_builders.default_TrainingStatisticExtractionCalculator
    cfg:
      dataset: '${dataset}'
      text_column: '${text_column}'
      label_column: '${label_column}'
      description: '${description}'
      prompt: '${prompt}'
      few_shot_split: '${few_shot_split}'
      train_split: '${train_split}'
      load_from_disk: '${load_from_disk}'
      subsample_train_dataset: '${subsample_train_dataset}'
      n_shot: '${n_shot}'
      max_subject_size: '${max_subject_size}'

      train_dataset: '${train_dataset}'
      train_test_split: '${train_test_split}'

      background_train_dataset: '${background_train_dataset}'
      background_train_dataset_text_column: '${background_train_dataset_text_column}'
      background_train_dataset_label_column: '${background_train_dataset_label_column}'
      background_train_dataset_data_files: '${background_train_dataset_data_files}'
      background_load_from_disk: '${background_load_from_disk}'
      subsample_background_train_dataset: '${subsample_background_train_dataset}'
      batch_size: '${batch_size}'

      seed: '${seed}'

    stats: 
      - "train_embeddings"
      - "background_train_embeddings"
      - "train_greedy_log_likelihoods"
    dependencies:


ignore_exceptions: false

batch_size: 1
deberta_batch_size: 10

seed:
    - 1
