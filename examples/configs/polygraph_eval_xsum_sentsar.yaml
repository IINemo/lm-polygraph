hydra:
  run:
    dir: ${cache_path}/${task}/${model.path}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: bloomz-560m
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

device: cpu

task: ats

dataset: xsum
text_column: document
label_column: summary
prompt: "Here's the text and it's short one-sentence summary.\n\nText:\n{text}\n\nSummary (one sentence):\n"
train_split: train
eval_split: test
max_new_tokens: 56
load_from_disk: false
trust_remote_code: true
generation_params:
  generate_until:
    - "\n"
save_stats:
  - sample_tokens
  - sample_texts
  - sample_log_probs
  - sample_sentence_similarity
entropy_top_k: 50

train_dataset: null
train_test_split: false
test_split_size: 1

background_train_dataset: allenai/c4
background_train_dataset_text_column: text
background_train_dataset_label_column: url
background_train_dataset_data_files: en/c4-train.00000-of-01024.json.gz
background_load_from_disk: false

subsample_background_train_dataset: 1000
subsample_train_dataset: 1000
subsample_eval_dataset: -1

use_density_based_ue: false
use_seq_ue: false
use_tok_ue: false
use_ens_ue: false

additional_estimators:
  - module: lm_polygraph.estimators.monte_carlo_sequence_entropy
    class_name: MonteCarloSequenceEntropy
    kwargs: {}
  - module: lm_polygraph.estimators.monte_carlo_normalized_sequence_entropy
    class_name: MonteCarloNormalizedSequenceEntropy
    kwargs: {}
  - module: lm_polygraph.estimators.semantic_entropy
    class_name: SemanticEntropy
    kwargs: {}

  - module: lm_polygraph.estimators.max_probability
    class_name: MaximumSequenceProbability
    kwargs: {}
  - module: lm_polygraph.estimators.sentence_sar
    class_name: SentenceSAR
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: MaxprobGSU
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: MaxprobGSU
    kwargs: 
      use_log: false
      reverse: false
  - module: lm_polygraph.estimators.gsu
    class_name: MaxprobGSU
    kwargs: 
      use_log: false
      reverse: true

  - module: lm_polygraph.estimators.token_sar
    class_name: TokenSAR
    kwargs: {}
  - module: lm_polygraph.estimators.sar
    class_name: SAR
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: TokenSARGSU
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: TokenSARGSU
    kwargs: 
      use_log: false
      reverse: false
  - module: lm_polygraph.estimators.gsu
    class_name: TokenSARGSU
    kwargs: 
      use_log: false
      reverse: true

  - module: lm_polygraph.estimators.perplexity
    class_name: Perplexity
    kwargs: {}
  - module: lm_polygraph.estimators.sentence_sar
    class_name: PPLSAR
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: PPLGSU
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: PPLGSU
    kwargs: 
      use_log: false
      reverse: false
  - module: lm_polygraph.estimators.gsu
    class_name: PPLGSU
    kwargs: 
      use_log: false
      reverse: true

  - module: lm_polygraph.estimators.token_entropy
    class_name: MeanTokenEntropy
    kwargs: {}
  - module: lm_polygraph.estimators.sentence_sar
    class_name: MTESAR
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: MTEGSU
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: MTEGSU
    kwargs: 
      use_log: false
      reverse: false
  - module: lm_polygraph.estimators.gsu
    class_name: MTEGSU
    kwargs: 
      use_log: false
      reverse: true

  - module: lm_polygraph.estimators.claim_conditioned_probability
    class_name: ClaimConditionedProbability
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: CCPGSU
    kwargs: {}
  - module: lm_polygraph.estimators.gsu
    class_name: CCPGSU
    kwargs: 
      use_log: false
      reverse: false
  - module: lm_polygraph.estimators.gsu
    class_name: CCPGSU
    kwargs: 
      use_log: false
      reverse: true

ignore_exceptions: false

batch_size: 1
deberta_batch_size: 1

seed:
    - 1
