hydra:
  run:
    dir: ${cache_path}/${task}/${model.path}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: bloomz-560m
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'
instruct: false
task: bio

dataset_name: wiki-bio
dataset: [wiki_bio]
n_shot: 0
text_column: input_text
label_column: null
prompt: "This is a Wikipedia passage about {context}:\n"
description: ""
few_shot_split: train
few_shot_prompt: null
eval_split: test
subsample_eval_dataset: 100
max_new_tokens: 256
load_from_disk: false
trust_remote_code: false

train_dataset: null
train_test_split: false
test_split_size: 1

use_density_based_ue: false
use_seq_ue: false
use_tok_ue: false
use_ens_ue: false
use_claim_ue: true
generation_metrics: [{
  'name': 'OpenAIFactCheck'
}]
ens_type:

ignore_exceptions: false

batch_size: 1

seed:
    - 1
