hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

device: cpu

task: nmt

dataset: [wmt14, de-en]
text_column: de
label_column: en
prompt: "Translate from {source_lang} into {target_lang}. Output only translation:\n{text}\nTranslation:\n"
train_split: train
eval_split: test
max_new_tokens: 107
load_from_disk: false

train_dataset: null
train_test_split: false
test_split_size: 1

background_train_dataset: allenai/c4
background_train_dataset_text_column: text
background_train_dataset_label_column: url
background_train_dataset_data_files: en/c4-train.00000-of-01024.json.gz
background_load_from_disk: false

subsample_background_train_dataset: 1000
subsample_train_dataset: 1000
subsample_eval_dataset: -1

model: databricks/dolly-v2-3b
use_auth_token:

use_density_based_ue: true
use_seq_ue: true
use_tok_ue: false

# Examples of providing additional UE methods:
# additional_estimators: {
#   'lm_polygraph.estimators.perplexity': ['Perplexity'],
#   'lm_polygraph.estimators.eig_val_laplacian': ['EigValLaplacian']
# }
# additional_estimators_kwargs: {
#   'Perplexity': {},
#   'EigValLaplacian': {'similarity_score': 'NLI_score', 'affinity': 'entail'}
# }

ignore_exceptions: false

batch_size: 1
deberta_batch_size: 10

seed:
    - 1
    
