hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

task: qa

defaults:
<<<<<<< HEAD
  - model: ugrip_llama_instruct
  # - dataset: ['UGRIP-LM-Polygraph/gsm8k-direct', 'default']
=======
  - model: ugrip_gemma_instruct
>>>>>>> origin/belati-syuhada
  - estimators: ugrip_benchmark_estimators
  - stat_calculators: default_calculators
  - _self_

<<<<<<< HEAD
dataset: ['UGRIP-LM-Polygraph/gsm8k-direct', 'default']
=======
task: qa
dataset: ['UGRIP-LM-Polygraph/gsm8k-direct']
>>>>>>> origin/belati-syuhada
text_column: question
label_column: answer
max_new_tokens: 20

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

train_split: train
eval_split: test
# few_shot_prompt: null
load_from_disk: false
normalize: true
trust_remote_code: false
# Limit to 10,000 samples? Is this bad?
size: 10000
generation_params:
  generate_until:
    - "\n"

<<<<<<< HEAD
subsample_eval_dataset: 10
=======
subsample_eval_dataset: 1
>>>>>>> origin/belati-syuhada

# generation_metrics: null

ignore_exceptions: false

batch_size: 1

seed:
    - 1
