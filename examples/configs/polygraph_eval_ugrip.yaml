hydra:
  run:
    dir: ${cache_path}/${task}/${model}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: ugrip_llama_instruct
  - estimators: ugrip_benchmark_estimators
  - stat_calculators: default_calculators
  - _self_

# OPTIONS:
#  UGRIP-LM-Polygraph/gsm8k-direct
#  UGRIP-LM-Polygraph/gsm8k-reasoning
#  UGRIP-LM-Polygraph/medmcqa-direct
#  UGRIP-LM-Polygraph/medmcqa-reasoning
#  UGRIP-LM-Polygraph/mmlu-direct
#  UGRIP-LM-POLYGRAPH/mmlu-reasoning
dataset: "UGRIP-LM-Polygraph/gsm8k-direct"

task: qa
text_column: question
label_column: answer
# Use max_new_tokens= to override
max_new_tokens: 500

process_output_fn:
  path: instruct/output_processing_scripts/ugrip.py
  fn_name: process_output
process_target_fn:
  path: instruct/output_processing_scripts/ugrip.py
  fn_name: process_target

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

train_split: train
eval_split: test
# few_shot_prompt: null
load_from_disk: false
normalize: false # REQUIRED TO ALLOW process_output_fn
trust_remote_code: false
generation_params:
  generate_until:
    - "\n"

# \/ How many samples per dataset
# Change with subsample_eval_dataset=25
subsample_eval_dataset: -1

# \/ What to ignore in model output
# output_ignore_regex: "(?s).### Answer: "
# Below is important for Gemma outputs
# output_ignore_regex: "<end_of_turn>"

ignore_exceptions: false

batch_size: 1

seed:
    - 1
