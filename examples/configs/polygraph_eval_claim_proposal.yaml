hydra:
  run:
    dir: ${cache_path}/${task}/${model.path}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: mistral-instruct-v2

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

task: bio

dataset_name: person-bio
dataset: [rediska0123/person-bio]
n_shot: 0
text_column: question
eval_split: test
max_new_tokens: 256
load_from_disk: false

train_dataset: null
train_test_split: false
test_split_size: 1

subsample_eval_dataset: -1

use_density_based_ue: false
use_seq_ue: false
use_tok_ue: false
use_ens_ue: false
use_claim_ue: true
generation_metrics: [{
  'name': 'OpenAIFactCheck'
}]
ens_type:

# Examples of providing additional UE methods:
# additional_estimators: {
#   'lm_polygraph.estimators.perplexity': ['Perplexity'],
#   'lm_polygraph.estimators.eig_val_laplacian': ['EigValLaplacian']
# }
# additional_estimators_kwargs: {
#   'Perplexity': {},
#   'EigValLaplacian': {'similarity_score': 'NLI_score', 'affinity': 'entail'}
# }

estimators:
  - name: MaximumClaimProbability
  - name: luq.builder_luq_claim_estimator
    cfg: 
      reduce_type: "mean"

stat_calculators:
  - auto
  - name: ClaimExtractor
    builder: lm_polygraph.defaults.stat_calculator_builders.default_ClaimsExtractor
    cfg:
      openai_model: "gpt-4"
      cache_path: "/home/artemshelmanov/.cache"
    stats: 
      - "claims"
      - "claim_texts_concatenated"
      - "claim_input_texts_concatenated"
    dependencies:
      - "greedy_texts"
      - "greedy_tokens"


batch_size: 1

seed:
    - 1

ignore_exceptions: false
