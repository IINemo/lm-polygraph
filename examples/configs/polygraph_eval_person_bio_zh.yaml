hydra:
  run:
    dir: ${cache_path}/${task}/${model.path}/${dataset}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model: bloomz-560m
  - default_claim_estimators
  - _self_

cache_path: ./workdir/output
save_path: '${hydra:run.dir}'

task: bio

dataset: ['LM-Polygraph/person_bio', 'zh']
text_column: input
eval_split: test
max_new_tokens: 256
load_from_disk: false

subsample_eval_dataset: -1

model:
  path: 01-ai/Yi-6B-Chat
  load_tokenizer_args: {"add_bos_token": false}

use_claim_ue: true
generation_metrics: [{
  'name': 'OpenAIFactCheck'
}]

stat_calculators:
  - auto
  - name: ClaimsExtractor
    builder: lm_polygraph.defaults.stat_calculator_builders.default_ClaimsExtractor
    cfg:
      openai_model: gpt-4o
      language: zh
      cache_path: ${cache_path}
    dependencies:
      - greedy_texts
      - greedy_tokens
    stats: 
      - claims
      - claim_texts_concatenated
      - claim_input_texts_concatenated

ignore_exceptions: false

batch_size: 1
language: zh

seed:
    - 1
